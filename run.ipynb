{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac6664b",
   "metadata": {},
   "source": [
    "# Run Program from Jupyter Notebook\n",
    "This notebook runs the Python program with arguments directly inside Jupyter."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get project from GitHub\n",
    "\n",
    "When working in Google Colab, use this to clone project."
   ],
   "id": "67cbd08e660fffe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Delete folder (if it already exists)\n",
    "!rm -rf Simple-Racecar-Rule-Agent\n",
    "\n",
    "!git clone https://github.com/timstengelin/Simple-Racecar-Rule-Agent.git\n",
    "%cd Simple-Racecar-Rule-Agent"
   ],
   "id": "dde03f9101091d4"
  },
  {
   "cell_type": "markdown",
   "id": "387198c8",
   "metadata": {},
   "source": [
    "## Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "id": "912c2347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T03:04:41.687275Z",
     "start_time": "2025-09-08T03:04:41.634728Z"
    }
   },
   "source": [
    "program_args = ['python3', 'Run.py', 'RuleAgent.py', '1']\n",
    "print('Current arguments:', program_args)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current arguments: ['python3', 'Run.py', 'RuleAgent.py', '1', '-g', '500']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "71f97946",
   "metadata": {},
   "source": [
    "## Run using `!` (shell command)\n",
    "The arguments are joined into a single command."
   ]
  },
  {
   "cell_type": "code",
   "id": "43b96cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T03:06:48.405862Z",
     "start_time": "2025-09-08T03:06:28.503030Z"
    }
   },
   "source": [
    "command = ' '.join(program_args)\n",
    "print('Running:', command)\n",
    "!{command}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python3 Run.py RuleAgent.py 1 -g 500\n",
      "Starting simulation\n",
      "Iteration 1.  State is <(-0.02, 10.42), 185.7, 0.05>.  Distance to center: 0.42, Distance from start 0.02, Lidar 0.88, 2.8, 4.7, 7.3, 1.9, Velocity 0.05, Choosing action ('right', 'accelerate'), reward 0.04 and totalReward 0.04.\n",
      "Iteration 2.  State is <(-0.10, 10.40), 191.7, 0.10>.  Distance to center: 0.40, Distance from start 0.09, Lidar 1.0, 3.8, 6.1, 8.9, 1.8, Velocity 0.10, Choosing action ('right', 'accelerate'), reward 0.11 and totalReward 0.15.\n",
      "Iteration 3.  State is <(-0.22, 10.37), 197.7, 0.15>.  Distance to center: 0.37, Distance from start 0.21, Lidar 1.2, 5.0, 7.6, 1.1e+01, 1.6, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 0.34.\n",
      "Iteration 4.  State is <(-0.34, 10.33), 203.7, 0.10>.  Distance to center: 0.33, Distance from start 0.33, Lidar 1.5, 6.4, 9.2, 3.5, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.18 and totalReward 0.52.\n",
      "Iteration 5.  State is <(-0.45, 10.29), 197.7, 0.15>.  Distance to center: 0.30, Distance from start 0.44, Lidar 1.3, 4.9, 7.4, 1e+01, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.18 and totalReward 0.70.\n",
      "Iteration 6.  State is <(-0.57, 10.24), 203.7, 0.10>.  Distance to center: 0.26, Distance from start 0.56, Lidar 1.6, 6.3, 9.0, 3.5, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.18 and totalReward 0.89.\n",
      "Iteration 7.  State is <(-0.69, 10.20), 197.7, 0.15>.  Distance to center: 0.22, Distance from start 0.67, Lidar 1.4, 4.8, 7.2, 9.9, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.19 and totalReward 1.07.\n",
      "Iteration 8.  State is <(-0.81, 10.16), 203.7, 0.10>.  Distance to center: 0.19, Distance from start 0.79, Lidar 1.6, 6.1, 8.7, 3.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.19 and totalReward 1.26.\n",
      "Iteration 9.  State is <(-0.92, 10.11), 197.7, 0.15>.  Distance to center: 0.16, Distance from start 0.91, Lidar 1.4, 4.7, 7.0, 9.6, 1.4, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.19 and totalReward 1.45.\n",
      "Iteration 10.  State is <(-1.04, 10.08), 191.7, 0.10>.  Distance to center: 0.13, Distance from start 1.03, Lidar 1.3, 3.6, 5.4, 7.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.19 and totalReward 1.64.\n",
      "Iteration 11.  State is <(-1.16, 10.05), 197.7, 0.15>.  Distance to center: 0.11, Distance from start 1.15, Lidar 1.5, 4.5, 6.7, 9.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 1.83.\n",
      "Iteration 12.  State is <(-1.28, 10.01), 191.7, 0.10>.  Distance to center: 0.10, Distance from start 1.27, Lidar 1.3, 3.5, 5.2, 7.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.19 and totalReward 2.03.\n",
      "Iteration 13.  State is <(-1.40, 9.98), 197.7, 0.15>.  Distance to center: 0.08, Distance from start 1.40, Lidar 1.5, 4.4, 6.4, 9.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 2.22.\n",
      "Iteration 14.  State is <(-1.52, 9.95), 191.7, 0.10>.  Distance to center: 0.07, Distance from start 1.52, Lidar 1.3, 3.4, 5.0, 7.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 2.42.\n",
      "Iteration 15.  State is <(-1.64, 9.92), 197.7, 0.15>.  Distance to center: 0.05, Distance from start 1.64, Lidar 1.5, 4.2, 6.1, 8.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 2.62.\n",
      "Iteration 16.  State is <(-1.77, 9.88), 191.7, 0.10>.  Distance to center: 0.04, Distance from start 1.77, Lidar 1.3, 3.3, 4.8, 6.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 2.81.\n",
      "Iteration 17.  State is <(-1.89, 9.85), 197.7, 0.15>.  Distance to center: 0.03, Distance from start 1.89, Lidar 1.5, 4.0, 5.9, 8.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.01.\n",
      "Iteration 18.  State is <(-2.01, 9.82), 191.7, 0.10>.  Distance to center: 0.02, Distance from start 2.02, Lidar 1.3, 3.1, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 3.21.\n",
      "Iteration 19.  State is <(-2.13, 9.78), 197.7, 0.15>.  Distance to center: 0.01, Distance from start 2.14, Lidar 1.5, 3.8, 5.6, 7.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.41.\n",
      "Iteration 20.  State is <(-2.25, 9.75), 191.7, 0.10>.  Distance to center: 0.01, Distance from start 2.26, Lidar 1.3, 3.0, 4.4, 6.3, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 3.60.\n",
      "Iteration 21.  State is <(-2.37, 9.72), 197.7, 0.15>.  Distance to center: 0.00, Distance from start 2.39, Lidar 1.4, 3.7, 5.3, 7.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.80.\n",
      "Iteration 22.  State is <(-2.49, 9.69), 191.7, 0.10>.  Distance to center: 0.00, Distance from start 2.51, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 4.00.\n",
      "Iteration 23.  State is <(-2.61, 9.65), 197.7, 0.15>.  Distance to center: 0.00, Distance from start 2.64, Lidar 1.4, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 4.20.\n",
      "Iteration 24.  State is <(-2.73, 9.61), 203.7, 0.10>.  Distance to center: 0.01, Distance from start 2.76, Lidar 1.6, 4.3, 6.2, 8.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 4.40.\n",
      "Iteration 25.  State is <(-2.84, 9.57), 197.7, 0.15>.  Distance to center: 0.02, Distance from start 2.89, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 4.60.\n",
      "Iteration 26.  State is <(-2.96, 9.52), 203.7, 0.10>.  Distance to center: 0.03, Distance from start 3.01, Lidar 1.5, 4.1, 5.9, 8.3, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 4.80.\n",
      "Iteration 27.  State is <(-3.08, 9.48), 197.7, 0.15>.  Distance to center: 0.03, Distance from start 3.14, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 4.99.\n",
      "Iteration 28.  State is <(-3.19, 9.44), 203.7, 0.10>.  Distance to center: 0.04, Distance from start 3.26, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.19.\n",
      "Iteration 29.  State is <(-3.31, 9.39), 197.7, 0.15>.  Distance to center: 0.04, Distance from start 3.39, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 5.39.\n",
      "Iteration 30.  State is <(-3.43, 9.35), 203.7, 0.10>.  Distance to center: 0.04, Distance from start 3.51, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.59.\n",
      "Iteration 31.  State is <(-3.55, 9.31), 197.7, 0.15>.  Distance to center: 0.04, Distance from start 3.64, Lidar 1.3, 2.9, 4.2, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 5.79.\n",
      "Iteration 32.  State is <(-3.66, 9.27), 203.7, 0.10>.  Distance to center: 0.04, Distance from start 3.76, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.99.\n",
      "Iteration 33.  State is <(-3.78, 9.22), 197.7, 0.15>.  Distance to center: 0.03, Distance from start 3.89, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 6.19.\n",
      "Iteration 34.  State is <(-3.90, 9.18), 203.7, 0.10>.  Distance to center: 0.03, Distance from start 4.02, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 6.39.\n",
      "Iteration 35.  State is <(-4.01, 9.12), 209.7, 0.15>.  Distance to center: 0.04, Distance from start 4.14, Lidar 1.5, 4.0, 5.8, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 6.59.\n",
      "Iteration 36.  State is <(-4.12, 9.07), 203.7, 0.10>.  Distance to center: 0.04, Distance from start 4.27, Lidar 1.4, 3.2, 4.6, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 6.79.\n",
      "Iteration 37.  State is <(-4.23, 9.01), 209.7, 0.15>.  Distance to center: 0.05, Distance from start 4.39, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 6.99.\n",
      "Iteration 38.  State is <(-4.34, 8.95), 203.7, 0.10>.  Distance to center: 0.05, Distance from start 4.52, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.19.\n",
      "Iteration 39.  State is <(-4.45, 8.89), 209.7, 0.15>.  Distance to center: 0.05, Distance from start 4.64, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 7.39.\n",
      "Iteration 40.  State is <(-4.56, 8.84), 203.7, 0.10>.  Distance to center: 0.06, Distance from start 4.77, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.59.\n",
      "Iteration 41.  State is <(-4.67, 8.78), 209.7, 0.15>.  Distance to center: 0.05, Distance from start 4.89, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 7.79.\n",
      "Iteration 42.  State is <(-4.78, 8.72), 203.7, 0.10>.  Distance to center: 0.05, Distance from start 5.02, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.99.\n",
      "Iteration 43.  State is <(-4.90, 8.66), 209.7, 0.15>.  Distance to center: 0.05, Distance from start 5.14, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 8.19.\n",
      "Iteration 44.  State is <(-5.01, 8.61), 203.7, 0.10>.  Distance to center: 0.04, Distance from start 5.27, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 8.39.\n",
      "Iteration 45.  State is <(-5.12, 8.55), 209.7, 0.15>.  Distance to center: 0.04, Distance from start 5.39, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 8.58.\n",
      "Iteration 46.  State is <(-5.22, 8.48), 215.7, 0.10>.  Distance to center: 0.04, Distance from start 5.52, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 8.78.\n",
      "Iteration 47.  State is <(-5.33, 8.42), 209.7, 0.15>.  Distance to center: 0.04, Distance from start 5.64, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 8.98.\n",
      "Iteration 48.  State is <(-5.43, 8.35), 215.7, 0.10>.  Distance to center: 0.04, Distance from start 5.77, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 9.18.\n",
      "Iteration 49.  State is <(-5.54, 8.28), 209.7, 0.15>.  Distance to center: 0.03, Distance from start 5.89, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 9.38.\n",
      "Iteration 50.  State is <(-5.65, 8.22), 215.7, 0.10>.  Distance to center: 0.03, Distance from start 6.02, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 9.58.\n",
      "Iteration 51.  State is <(-5.74, 8.14), 221.7, 0.15>.  Distance to center: 0.04, Distance from start 6.14, Lidar 1.6, 4.1, 5.9, 8.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 9.78.\n",
      "Iteration 52.  State is <(-5.84, 8.06), 215.7, 0.10>.  Distance to center: 0.05, Distance from start 6.27, Lidar 1.4, 3.2, 4.6, 6.7, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 9.98.\n",
      "Iteration 53.  State is <(-5.94, 7.98), 221.7, 0.15>.  Distance to center: 0.05, Distance from start 6.40, Lidar 1.5, 3.9, 5.7, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 10.18.\n",
      "Iteration 54.  State is <(-6.03, 7.90), 215.7, 0.10>.  Distance to center: 0.06, Distance from start 6.52, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 10.38.\n",
      "Iteration 55.  State is <(-6.13, 7.82), 221.7, 0.15>.  Distance to center: 0.06, Distance from start 6.65, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 10.58.\n",
      "Iteration 56.  State is <(-6.23, 7.74), 215.7, 0.10>.  Distance to center: 0.06, Distance from start 6.77, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 10.78.\n",
      "Iteration 57.  State is <(-6.32, 7.66), 221.7, 0.15>.  Distance to center: 0.06, Distance from start 6.90, Lidar 1.5, 3.6, 5.1, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 10.98.\n",
      "Iteration 58.  State is <(-6.42, 7.59), 215.7, 0.10>.  Distance to center: 0.06, Distance from start 7.02, Lidar 1.4, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 11.18.\n",
      "Iteration 59.  State is <(-6.52, 7.51), 221.7, 0.15>.  Distance to center: 0.06, Distance from start 7.15, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 11.38.\n",
      "Iteration 60.  State is <(-6.61, 7.43), 215.7, 0.10>.  Distance to center: 0.06, Distance from start 7.27, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 11.58.\n",
      "Iteration 61.  State is <(-6.71, 7.35), 221.7, 0.15>.  Distance to center: 0.05, Distance from start 7.40, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 11.78.\n",
      "Iteration 62.  State is <(-6.80, 7.26), 227.7, 0.10>.  Distance to center: 0.05, Distance from start 7.52, Lidar 1.5, 3.9, 5.6, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 11.98.\n",
      "Iteration 63.  State is <(-6.89, 7.17), 221.7, 0.15>.  Distance to center: 0.05, Distance from start 7.65, Lidar 1.4, 3.1, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 12.18.\n",
      "Iteration 64.  State is <(-6.98, 7.09), 227.7, 0.10>.  Distance to center: 0.05, Distance from start 7.78, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 12.38.\n",
      "Iteration 65.  State is <(-7.07, 7.00), 221.7, 0.15>.  Distance to center: 0.05, Distance from start 7.90, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 12.58.\n",
      "Iteration 66.  State is <(-7.16, 6.91), 227.7, 0.10>.  Distance to center: 0.05, Distance from start 8.03, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 12.78.\n",
      "Iteration 67.  State is <(-7.25, 6.83), 221.7, 0.15>.  Distance to center: 0.04, Distance from start 8.15, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 12.97.\n",
      "Iteration 68.  State is <(-7.34, 6.74), 227.7, 0.10>.  Distance to center: 0.04, Distance from start 8.28, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 13.17.\n",
      "Iteration 69.  State is <(-7.41, 6.64), 233.7, 0.15>.  Distance to center: 0.05, Distance from start 8.40, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 13.37.\n",
      "Iteration 70.  State is <(-7.49, 6.54), 227.7, 0.10>.  Distance to center: 0.05, Distance from start 8.53, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 13.57.\n",
      "Iteration 71.  State is <(-7.57, 6.45), 233.7, 0.15>.  Distance to center: 0.06, Distance from start 8.65, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 13.77.\n",
      "Iteration 72.  State is <(-7.65, 6.35), 227.7, 0.10>.  Distance to center: 0.06, Distance from start 8.78, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 13.97.\n",
      "Iteration 73.  State is <(-7.73, 6.25), 233.7, 0.15>.  Distance to center: 0.06, Distance from start 8.90, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.17.\n",
      "Iteration 74.  State is <(-7.80, 6.16), 227.7, 0.10>.  Distance to center: 0.06, Distance from start 9.03, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 14.37.\n",
      "Iteration 75.  State is <(-7.88, 6.06), 233.7, 0.15>.  Distance to center: 0.06, Distance from start 9.16, Lidar 1.5, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.57.\n",
      "Iteration 76.  State is <(-7.96, 5.96), 227.7, 0.10>.  Distance to center: 0.06, Distance from start 9.28, Lidar 1.3, 2.7, 3.8, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 14.77.\n",
      "Iteration 77.  State is <(-8.04, 5.86), 233.7, 0.15>.  Distance to center: 0.05, Distance from start 9.41, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.97.\n",
      "Iteration 78.  State is <(-8.11, 5.76), 239.7, 0.10>.  Distance to center: 0.05, Distance from start 9.53, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 15.17.\n",
      "Iteration 79.  State is <(-8.18, 5.66), 233.7, 0.15>.  Distance to center: 0.06, Distance from start 9.66, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 15.37.\n",
      "Iteration 80.  State is <(-8.25, 5.55), 239.7, 0.10>.  Distance to center: 0.06, Distance from start 9.78, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 15.57.\n",
      "Iteration 81.  State is <(-8.32, 5.45), 233.7, 0.15>.  Distance to center: 0.06, Distance from start 9.91, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 15.77.\n",
      "Iteration 82.  State is <(-8.39, 5.34), 239.7, 0.10>.  Distance to center: 0.06, Distance from start 10.03, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 15.97.\n",
      "Iteration 83.  State is <(-8.46, 5.24), 233.7, 0.15>.  Distance to center: 0.05, Distance from start 10.16, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 16.17.\n",
      "Iteration 84.  State is <(-8.53, 5.14), 239.7, 0.10>.  Distance to center: 0.05, Distance from start 10.28, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 16.37.\n",
      "Iteration 85.  State is <(-8.60, 5.03), 233.7, 0.15>.  Distance to center: 0.04, Distance from start 10.41, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 16.57.\n",
      "Iteration 86.  State is <(-8.66, 4.93), 239.7, 0.10>.  Distance to center: 0.03, Distance from start 10.54, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 16.77.\n",
      "Iteration 87.  State is <(-8.72, 4.82), 245.7, 0.15>.  Distance to center: 0.04, Distance from start 10.66, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 16.97.\n",
      "Iteration 88.  State is <(-8.78, 4.71), 239.7, 0.10>.  Distance to center: 0.04, Distance from start 10.79, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 17.17.\n",
      "Iteration 89.  State is <(-8.83, 4.60), 245.7, 0.15>.  Distance to center: 0.04, Distance from start 10.91, Lidar 1.5, 3.6, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 17.36.\n",
      "Iteration 90.  State is <(-8.89, 4.48), 239.7, 0.10>.  Distance to center: 0.04, Distance from start 11.04, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 17.56.\n",
      "Iteration 91.  State is <(-8.95, 4.37), 245.7, 0.15>.  Distance to center: 0.04, Distance from start 11.16, Lidar 1.4, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 17.76.\n",
      "Iteration 92.  State is <(-9.00, 4.26), 239.7, 0.10>.  Distance to center: 0.04, Distance from start 11.29, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 17.96.\n",
      "Iteration 93.  State is <(-9.06, 4.15), 245.7, 0.15>.  Distance to center: 0.04, Distance from start 11.41, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 18.16.\n",
      "Iteration 94.  State is <(-9.10, 4.03), 251.7, 0.10>.  Distance to center: 0.04, Distance from start 11.54, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 18.36.\n",
      "Iteration 95.  State is <(-9.15, 3.92), 245.7, 0.15>.  Distance to center: 0.05, Distance from start 11.66, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 18.56.\n",
      "Iteration 96.  State is <(-9.20, 3.80), 251.7, 0.10>.  Distance to center: 0.05, Distance from start 11.79, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 18.76.\n",
      "Iteration 97.  State is <(-9.24, 3.69), 245.7, 0.15>.  Distance to center: 0.05, Distance from start 11.91, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 18.96.\n",
      "Iteration 98.  State is <(-9.29, 3.57), 251.7, 0.10>.  Distance to center: 0.05, Distance from start 12.04, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.16.\n",
      "Iteration 99.  State is <(-9.34, 3.45), 245.7, 0.15>.  Distance to center: 0.05, Distance from start 12.16, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 19.36.\n",
      "Iteration 100.  State is <(-9.38, 3.34), 251.7, 0.10>.  Distance to center: 0.04, Distance from start 12.29, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.56.\n",
      "Iteration 101.  State is <(-9.43, 3.22), 245.7, 0.15>.  Distance to center: 0.04, Distance from start 12.41, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 19.76.\n",
      "Iteration 102.  State is <(-9.48, 3.11), 251.7, 0.10>.  Distance to center: 0.03, Distance from start 12.54, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.96.\n",
      "Iteration 103.  State is <(-9.51, 2.99), 257.7, 0.15>.  Distance to center: 0.03, Distance from start 12.66, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 20.16.\n",
      "Iteration 104.  State is <(-9.54, 2.87), 251.7, 0.10>.  Distance to center: 0.04, Distance from start 12.79, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 20.36.\n",
      "Iteration 105.  State is <(-9.57, 2.74), 257.7, 0.15>.  Distance to center: 0.04, Distance from start 12.92, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 20.56.\n",
      "Iteration 106.  State is <(-9.60, 2.62), 251.7, 0.10>.  Distance to center: 0.05, Distance from start 13.04, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 20.76.\n",
      "Iteration 107.  State is <(-9.63, 2.50), 257.7, 0.15>.  Distance to center: 0.05, Distance from start 13.17, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 20.95.\n",
      "Iteration 108.  State is <(-9.67, 2.38), 251.7, 0.10>.  Distance to center: 0.04, Distance from start 13.29, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 21.15.\n",
      "Iteration 109.  State is <(-9.70, 2.26), 257.7, 0.15>.  Distance to center: 0.04, Distance from start 13.42, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 21.35.\n",
      "Iteration 110.  State is <(-9.73, 2.14), 251.7, 0.10>.  Distance to center: 0.04, Distance from start 13.54, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 21.55.\n",
      "Iteration 111.  State is <(-9.76, 2.02), 257.7, 0.15>.  Distance to center: 0.03, Distance from start 13.67, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 21.75.\n",
      "Iteration 112.  State is <(-9.78, 1.90), 263.7, 0.10>.  Distance to center: 0.04, Distance from start 13.79, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 21.95.\n",
      "Iteration 113.  State is <(-9.80, 1.77), 257.7, 0.15>.  Distance to center: 0.04, Distance from start 13.92, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 22.15.\n",
      "Iteration 114.  State is <(-9.83, 1.65), 263.7, 0.10>.  Distance to center: 0.04, Distance from start 14.04, Lidar 1.5, 3.6, 5.3, 7.5, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 22.35.\n",
      "Iteration 115.  State is <(-9.85, 1.53), 257.7, 0.15>.  Distance to center: 0.04, Distance from start 14.17, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 22.55.\n",
      "Iteration 116.  State is <(-9.87, 1.41), 263.7, 0.10>.  Distance to center: 0.03, Distance from start 14.29, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 22.75.\n",
      "Iteration 117.  State is <(-9.89, 1.28), 257.7, 0.15>.  Distance to center: 0.03, Distance from start 14.42, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 22.95.\n",
      "Iteration 118.  State is <(-9.91, 1.16), 263.7, 0.10>.  Distance to center: 0.02, Distance from start 14.54, Lidar 1.4, 3.3, 4.7, 6.8, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 23.15.\n",
      "Iteration 119.  State is <(-9.92, 1.03), 269.7, 0.15>.  Distance to center: 0.03, Distance from start 14.67, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 23.35.\n",
      "Iteration 120.  State is <(-9.92, 0.91), 263.7, 0.10>.  Distance to center: 0.04, Distance from start 14.79, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 23.54.\n",
      "Iteration 121.  State is <(-9.93, 0.78), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 14.92, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 23.74.\n",
      "Iteration 122.  State is <(-9.93, 0.66), 263.7, 0.10>.  Distance to center: 0.04, Distance from start 15.04, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 23.94.\n",
      "Iteration 123.  State is <(-9.94, 0.54), 269.7, 0.15>.  Distance to center: 0.05, Distance from start 15.17, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.14.\n",
      "Iteration 124.  State is <(-9.95, 0.41), 263.7, 0.10>.  Distance to center: 0.05, Distance from start 15.30, Lidar 1.3, 2.9, 4.0, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 24.34.\n",
      "Iteration 125.  State is <(-9.95, 0.29), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 15.42, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.54.\n",
      "Iteration 126.  State is <(-9.96, 0.16), 263.7, 0.10>.  Distance to center: 0.04, Distance from start 15.55, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 24.74.\n",
      "Iteration 127.  State is <(-9.96, 0.04), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 15.67, Lidar 1.4, 3.2, 4.6, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.94.\n",
      "Iteration 128.  State is <(-9.96, -0.09), 275.7, 0.10>.  Distance to center: 0.04, Distance from start 15.80, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 25.14.\n",
      "Iteration 129.  State is <(-9.95, -0.21), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 15.92, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 25.34.\n",
      "Iteration 130.  State is <(-9.95, -0.34), 275.7, 0.10>.  Distance to center: 0.04, Distance from start 16.05, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 25.54.\n",
      "Iteration 131.  State is <(-9.95, -0.46), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 16.17, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 25.74.\n",
      "Iteration 132.  State is <(-9.94, -0.59), 275.7, 0.10>.  Distance to center: 0.04, Distance from start 16.30, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 25.94.\n",
      "Iteration 133.  State is <(-9.94, -0.71), 269.7, 0.15>.  Distance to center: 0.04, Distance from start 16.42, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 26.14.\n",
      "Iteration 134.  State is <(-9.93, -0.84), 275.7, 0.10>.  Distance to center: 0.03, Distance from start 16.55, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 26.34.\n",
      "Iteration 135.  State is <(-9.91, -0.96), 281.7, 0.15>.  Distance to center: 0.04, Distance from start 16.67, Lidar 1.6, 4.1, 5.9, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 26.54.\n",
      "Iteration 136.  State is <(-9.89, -1.08), 275.7, 0.10>.  Distance to center: 0.05, Distance from start 16.80, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 26.74.\n",
      "Iteration 137.  State is <(-9.87, -1.21), 281.7, 0.15>.  Distance to center: 0.06, Distance from start 16.92, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 26.94.\n",
      "Iteration 138.  State is <(-9.85, -1.33), 275.7, 0.10>.  Distance to center: 0.06, Distance from start 17.05, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 27.13.\n",
      "Iteration 139.  State is <(-9.83, -1.45), 281.7, 0.15>.  Distance to center: 0.06, Distance from start 17.17, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 27.33.\n",
      "Iteration 140.  State is <(-9.81, -1.58), 275.7, 0.10>.  Distance to center: 0.06, Distance from start 17.30, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 27.53.\n",
      "Iteration 141.  State is <(-9.79, -1.70), 281.7, 0.15>.  Distance to center: 0.06, Distance from start 17.43, Lidar 1.5, 3.5, 5.1, 7.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 27.73.\n",
      "Iteration 142.  State is <(-9.77, -1.82), 275.7, 0.10>.  Distance to center: 0.06, Distance from start 17.55, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 27.93.\n",
      "Iteration 143.  State is <(-9.75, -1.95), 281.7, 0.15>.  Distance to center: 0.06, Distance from start 17.68, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 28.13.\n",
      "Iteration 144.  State is <(-9.73, -2.07), 275.7, 0.10>.  Distance to center: 0.05, Distance from start 17.80, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 28.33.\n",
      "Iteration 145.  State is <(-9.71, -2.19), 281.7, 0.15>.  Distance to center: 0.05, Distance from start 17.93, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 28.53.\n",
      "Iteration 146.  State is <(-9.68, -2.31), 287.7, 0.10>.  Distance to center: 0.05, Distance from start 18.05, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 28.73.\n",
      "Iteration 147.  State is <(-9.65, -2.43), 281.7, 0.15>.  Distance to center: 0.05, Distance from start 18.18, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 28.93.\n",
      "Iteration 148.  State is <(-9.62, -2.55), 287.7, 0.10>.  Distance to center: 0.05, Distance from start 18.30, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.13.\n",
      "Iteration 149.  State is <(-9.59, -2.68), 281.7, 0.15>.  Distance to center: 0.05, Distance from start 18.43, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 29.33.\n",
      "Iteration 150.  State is <(-9.56, -2.80), 287.7, 0.10>.  Distance to center: 0.04, Distance from start 18.56, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.53.\n",
      "Iteration 151.  State is <(-9.53, -2.92), 281.7, 0.15>.  Distance to center: 0.04, Distance from start 18.68, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 29.73.\n",
      "Iteration 152.  State is <(-9.50, -3.04), 287.7, 0.10>.  Distance to center: 0.03, Distance from start 18.81, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.93.\n",
      "Iteration 153.  State is <(-9.45, -3.16), 293.7, 0.15>.  Distance to center: 0.04, Distance from start 18.93, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 30.13.\n",
      "Iteration 154.  State is <(-9.41, -3.27), 287.7, 0.10>.  Distance to center: 0.04, Distance from start 19.06, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 30.33.\n",
      "Iteration 155.  State is <(-9.36, -3.39), 293.7, 0.15>.  Distance to center: 0.05, Distance from start 19.18, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 30.53.\n",
      "Iteration 156.  State is <(-9.31, -3.50), 287.7, 0.10>.  Distance to center: 0.05, Distance from start 19.31, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 30.73.\n",
      "Iteration 157.  State is <(-9.27, -3.62), 293.7, 0.15>.  Distance to center: 0.05, Distance from start 19.43, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 30.93.\n",
      "Iteration 158.  State is <(-9.22, -3.74), 287.7, 0.10>.  Distance to center: 0.05, Distance from start 19.56, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 31.13.\n",
      "Iteration 159.  State is <(-9.18, -3.85), 293.7, 0.15>.  Distance to center: 0.05, Distance from start 19.68, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 31.33.\n",
      "Iteration 160.  State is <(-9.13, -3.97), 287.7, 0.10>.  Distance to center: 0.04, Distance from start 19.81, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 31.53.\n",
      "Iteration 161.  State is <(-9.09, -4.09), 293.7, 0.15>.  Distance to center: 0.04, Distance from start 19.93, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 31.72.\n",
      "Iteration 162.  State is <(-9.03, -4.20), 299.7, 0.10>.  Distance to center: 0.04, Distance from start 20.06, Lidar 1.5, 3.8, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 31.92.\n",
      "Iteration 163.  State is <(-8.98, -4.31), 293.7, 0.15>.  Distance to center: 0.04, Distance from start 20.18, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 32.12.\n",
      "Iteration 164.  State is <(-8.92, -4.42), 299.7, 0.10>.  Distance to center: 0.04, Distance from start 20.31, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 32.32.\n",
      "Iteration 165.  State is <(-8.87, -4.53), 293.7, 0.15>.  Distance to center: 0.04, Distance from start 20.43, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 32.52.\n",
      "Iteration 166.  State is <(-8.81, -4.65), 299.7, 0.10>.  Distance to center: 0.04, Distance from start 20.56, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 32.72.\n",
      "Iteration 167.  State is <(-8.76, -4.76), 293.7, 0.15>.  Distance to center: 0.03, Distance from start 20.68, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 32.92.\n",
      "Iteration 168.  State is <(-8.70, -4.87), 299.7, 0.10>.  Distance to center: 0.03, Distance from start 20.81, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 33.12.\n",
      "Iteration 169.  State is <(-8.63, -4.97), 305.7, 0.15>.  Distance to center: 0.04, Distance from start 20.93, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 33.32.\n",
      "Iteration 170.  State is <(-8.57, -5.08), 299.7, 0.10>.  Distance to center: 0.04, Distance from start 21.06, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 33.52.\n",
      "Iteration 171.  State is <(-8.50, -5.18), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 21.19, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 33.72.\n",
      "Iteration 172.  State is <(-8.43, -5.29), 299.7, 0.10>.  Distance to center: 0.05, Distance from start 21.31, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 33.92.\n",
      "Iteration 173.  State is <(-8.36, -5.39), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 21.44, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.12.\n",
      "Iteration 174.  State is <(-8.29, -5.50), 299.7, 0.10>.  Distance to center: 0.05, Distance from start 21.56, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 34.32.\n",
      "Iteration 175.  State is <(-8.22, -5.60), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 21.69, Lidar 1.5, 3.4, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.52.\n",
      "Iteration 176.  State is <(-8.15, -5.70), 299.7, 0.10>.  Distance to center: 0.05, Distance from start 21.81, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 34.72.\n",
      "Iteration 177.  State is <(-8.09, -5.81), 305.7, 0.15>.  Distance to center: 0.04, Distance from start 21.94, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.92.\n",
      "Iteration 178.  State is <(-8.01, -5.91), 311.7, 0.10>.  Distance to center: 0.05, Distance from start 22.06, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 35.11.\n",
      "Iteration 179.  State is <(-7.93, -6.01), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 22.19, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 35.31.\n",
      "Iteration 180.  State is <(-7.85, -6.10), 311.7, 0.10>.  Distance to center: 0.05, Distance from start 22.31, Lidar 1.5, 3.8, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 35.51.\n",
      "Iteration 181.  State is <(-7.78, -6.20), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 22.44, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 35.71.\n",
      "Iteration 182.  State is <(-7.70, -6.30), 311.7, 0.10>.  Distance to center: 0.05, Distance from start 22.57, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 35.91.\n",
      "Iteration 183.  State is <(-7.62, -6.40), 305.7, 0.15>.  Distance to center: 0.05, Distance from start 22.69, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 36.11.\n",
      "Iteration 184.  State is <(-7.55, -6.50), 311.7, 0.10>.  Distance to center: 0.04, Distance from start 22.82, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 36.31.\n",
      "Iteration 185.  State is <(-7.47, -6.60), 305.7, 0.15>.  Distance to center: 0.04, Distance from start 22.94, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 36.51.\n",
      "Iteration 186.  State is <(-7.39, -6.69), 311.7, 0.10>.  Distance to center: 0.03, Distance from start 23.07, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 36.71.\n",
      "Iteration 187.  State is <(-7.30, -6.78), 317.7, 0.15>.  Distance to center: 0.03, Distance from start 23.19, Lidar 1.5, 3.8, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 36.91.\n",
      "Iteration 188.  State is <(-7.21, -6.87), 311.7, 0.10>.  Distance to center: 0.04, Distance from start 23.32, Lidar 1.4, 3.0, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 37.11.\n",
      "Iteration 189.  State is <(-7.13, -6.96), 317.7, 0.15>.  Distance to center: 0.04, Distance from start 23.44, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 37.31.\n",
      "Iteration 190.  State is <(-7.04, -7.04), 311.7, 0.10>.  Distance to center: 0.04, Distance from start 23.57, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 37.51.\n",
      "Iteration 191.  State is <(-6.95, -7.13), 317.7, 0.15>.  Distance to center: 0.04, Distance from start 23.69, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 37.71.\n",
      "Iteration 192.  State is <(-6.86, -7.22), 311.7, 0.10>.  Distance to center: 0.04, Distance from start 23.82, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 37.91.\n",
      "Iteration 193.  State is <(-6.77, -7.31), 317.7, 0.15>.  Distance to center: 0.04, Distance from start 23.94, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 38.11.\n",
      "Iteration 194.  State is <(-6.68, -7.39), 323.7, 0.10>.  Distance to center: 0.04, Distance from start 24.07, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 38.31.\n",
      "Iteration 195.  State is <(-6.58, -7.47), 317.7, 0.15>.  Distance to center: 0.05, Distance from start 24.19, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 38.51.\n",
      "Iteration 196.  State is <(-6.48, -7.55), 323.7, 0.10>.  Distance to center: 0.05, Distance from start 24.32, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 38.70.\n",
      "Iteration 197.  State is <(-6.39, -7.63), 317.7, 0.15>.  Distance to center: 0.05, Distance from start 24.44, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 38.90.\n",
      "Iteration 198.  State is <(-6.29, -7.71), 323.7, 0.10>.  Distance to center: 0.05, Distance from start 24.57, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.10.\n",
      "Iteration 199.  State is <(-6.20, -7.79), 317.7, 0.15>.  Distance to center: 0.05, Distance from start 24.70, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 39.30.\n",
      "Iteration 200.  State is <(-6.10, -7.87), 323.7, 0.10>.  Distance to center: 0.04, Distance from start 24.82, Lidar 1.4, 3.4, 4.9, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.50.\n",
      "Iteration 201.  State is <(-6.00, -7.95), 317.7, 0.15>.  Distance to center: 0.04, Distance from start 24.95, Lidar 1.3, 2.7, 3.8, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 39.70.\n",
      "Iteration 202.  State is <(-5.91, -8.03), 323.7, 0.10>.  Distance to center: 0.03, Distance from start 25.07, Lidar 1.4, 3.2, 4.7, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.90.\n",
      "Iteration 203.  State is <(-5.80, -8.10), 329.7, 0.15>.  Distance to center: 0.04, Distance from start 25.20, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 40.10.\n",
      "Iteration 204.  State is <(-5.70, -8.16), 323.7, 0.10>.  Distance to center: 0.04, Distance from start 25.32, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 40.30.\n",
      "Iteration 205.  State is <(-5.59, -8.23), 329.7, 0.15>.  Distance to center: 0.05, Distance from start 25.45, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 40.50.\n",
      "Iteration 206.  State is <(-5.49, -8.30), 323.7, 0.10>.  Distance to center: 0.05, Distance from start 25.57, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 40.70.\n",
      "Iteration 207.  State is <(-5.38, -8.37), 329.7, 0.15>.  Distance to center: 0.05, Distance from start 25.70, Lidar 1.5, 3.6, 5.1, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 40.90.\n",
      "Iteration 208.  State is <(-5.28, -8.43), 323.7, 0.10>.  Distance to center: 0.05, Distance from start 25.82, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 41.10.\n",
      "Iteration 209.  State is <(-5.17, -8.50), 329.7, 0.15>.  Distance to center: 0.05, Distance from start 25.95, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 41.30.\n",
      "Iteration 210.  State is <(-5.07, -8.57), 323.7, 0.10>.  Distance to center: 0.05, Distance from start 26.07, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 41.50.\n",
      "Iteration 211.  State is <(-4.96, -8.63), 329.7, 0.15>.  Distance to center: 0.04, Distance from start 26.20, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 41.70.\n",
      "Iteration 212.  State is <(-4.85, -8.69), 335.7, 0.10>.  Distance to center: 0.04, Distance from start 26.32, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 41.90.\n",
      "Iteration 213.  State is <(-4.74, -8.75), 329.7, 0.15>.  Distance to center: 0.05, Distance from start 26.45, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 42.10.\n",
      "Iteration 214.  State is <(-4.63, -8.81), 335.7, 0.10>.  Distance to center: 0.05, Distance from start 26.58, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 42.30.\n",
      "Iteration 215.  State is <(-4.52, -8.87), 329.7, 0.15>.  Distance to center: 0.05, Distance from start 26.70, Lidar 1.4, 2.9, 4.1, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 42.50.\n",
      "Iteration 216.  State is <(-4.41, -8.93), 335.7, 0.10>.  Distance to center: 0.04, Distance from start 26.83, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 42.69.\n",
      "Iteration 217.  State is <(-4.30, -8.99), 329.7, 0.15>.  Distance to center: 0.04, Distance from start 26.95, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 42.89.\n",
      "Iteration 218.  State is <(-4.19, -9.04), 335.7, 0.10>.  Distance to center: 0.03, Distance from start 27.08, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 43.09.\n",
      "Iteration 219.  State is <(-4.07, -9.09), 341.7, 0.15>.  Distance to center: 0.04, Distance from start 27.20, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 43.29.\n",
      "Iteration 220.  State is <(-3.96, -9.13), 335.7, 0.10>.  Distance to center: 0.05, Distance from start 27.33, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 43.49.\n",
      "Iteration 221.  State is <(-3.84, -9.18), 341.7, 0.15>.  Distance to center: 0.05, Distance from start 27.45, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 43.69.\n",
      "Iteration 222.  State is <(-3.72, -9.22), 335.7, 0.10>.  Distance to center: 0.06, Distance from start 27.58, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 43.89.\n",
      "Iteration 223.  State is <(-3.61, -9.26), 341.7, 0.15>.  Distance to center: 0.06, Distance from start 27.70, Lidar 1.5, 3.6, 5.3, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.09.\n",
      "Iteration 224.  State is <(-3.49, -9.31), 335.7, 0.10>.  Distance to center: 0.06, Distance from start 27.83, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 44.29.\n",
      "Iteration 225.  State is <(-3.37, -9.35), 341.7, 0.15>.  Distance to center: 0.06, Distance from start 27.95, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.49.\n",
      "Iteration 226.  State is <(-3.26, -9.40), 335.7, 0.10>.  Distance to center: 0.06, Distance from start 28.08, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 44.69.\n",
      "Iteration 227.  State is <(-3.14, -9.44), 341.7, 0.15>.  Distance to center: 0.05, Distance from start 28.20, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.89.\n",
      "Iteration 228.  State is <(-3.02, -9.48), 335.7, 0.10>.  Distance to center: 0.05, Distance from start 28.33, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 45.09.\n",
      "Iteration 229.  State is <(-2.91, -9.53), 341.7, 0.15>.  Distance to center: 0.04, Distance from start 28.46, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 45.29.\n",
      "Iteration 230.  State is <(-2.79, -9.56), 347.7, 0.10>.  Distance to center: 0.04, Distance from start 28.58, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 45.49.\n",
      "Iteration 231.  State is <(-2.67, -9.60), 341.7, 0.15>.  Distance to center: 0.04, Distance from start 28.71, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 45.69.\n",
      "Iteration 232.  State is <(-2.55, -9.63), 347.7, 0.10>.  Distance to center: 0.04, Distance from start 28.83, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 45.89.\n",
      "Iteration 233.  State is <(-2.43, -9.67), 341.7, 0.15>.  Distance to center: 0.03, Distance from start 28.96, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 46.09.\n",
      "Iteration 234.  State is <(-2.31, -9.70), 347.7, 0.10>.  Distance to center: 0.03, Distance from start 29.08, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 46.29.\n",
      "Iteration 235.  State is <(-2.18, -9.72), 353.7, 0.15>.  Distance to center: 0.04, Distance from start 29.21, Lidar 1.6, 4.1, 5.9, 8.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 46.48.\n",
      "Iteration 236.  State is <(-2.06, -9.74), 347.7, 0.10>.  Distance to center: 0.05, Distance from start 29.33, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 46.68.\n",
      "Iteration 237.  State is <(-1.94, -9.76), 353.7, 0.15>.  Distance to center: 0.05, Distance from start 29.46, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 46.88.\n",
      "Iteration 238.  State is <(-1.81, -9.78), 347.7, 0.10>.  Distance to center: 0.06, Distance from start 29.58, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 47.08.\n",
      "Iteration 239.  State is <(-1.69, -9.79), 353.7, 0.15>.  Distance to center: 0.06, Distance from start 29.71, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 47.28.\n",
      "Iteration 240.  State is <(-1.57, -9.81), 347.7, 0.10>.  Distance to center: 0.06, Distance from start 29.83, Lidar 1.4, 3.0, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 47.48.\n",
      "Iteration 241.  State is <(-1.44, -9.83), 353.7, 0.15>.  Distance to center: 0.06, Distance from start 29.96, Lidar 1.5, 3.5, 5.1, 7.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 47.68.\n",
      "Iteration 242.  State is <(-1.32, -9.85), 347.7, 0.10>.  Distance to center: 0.06, Distance from start 30.08, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 47.88.\n",
      "Iteration 243.  State is <(-1.20, -9.87), 353.7, 0.15>.  Distance to center: 0.06, Distance from start 30.21, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 48.08.\n",
      "Iteration 244.  State is <(-1.07, -9.89), 347.7, 0.10>.  Distance to center: 0.05, Distance from start 30.34, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 48.28.\n",
      "Iteration 245.  State is <(-0.95, -9.91), 353.7, 0.15>.  Distance to center: 0.05, Distance from start 30.46, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 48.48.\n",
      "Iteration 246.  State is <(-0.82, -9.92), 359.7, 0.10>.  Distance to center: 0.05, Distance from start 30.59, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 48.68.\n",
      "Iteration 247.  State is <(-0.70, -9.92), 353.7, 0.15>.  Distance to center: 0.05, Distance from start 30.71, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 48.88.\n",
      "Iteration 248.  State is <(-0.58, -9.93), 359.7, 0.10>.  Distance to center: 0.05, Distance from start 30.84, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.08.\n",
      "Iteration 249.  State is <(-0.45, -9.94), 353.7, 0.15>.  Distance to center: 0.05, Distance from start 30.96, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 49.28.\n",
      "Iteration 250.  State is <(-0.33, -9.95), 359.7, 0.10>.  Distance to center: 0.05, Distance from start 31.09, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.48.\n",
      "Iteration 251.  State is <(-0.20, -9.96), 353.7, 0.15>.  Distance to center: 0.04, Distance from start 31.21, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 49.68.\n",
      "Iteration 252.  State is <(-0.08, -9.97), 359.7, 0.10>.  Distance to center: 0.03, Distance from start 31.34, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.88.\n",
      "Iteration 253.  State is <(0.05, -9.96), 5.7, 0.15>.  Distance to center: 0.04, Distance from start 31.46, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 50.08.\n",
      "Iteration 254.  State is <(0.17, -9.95), -0.3, 0.10>.  Distance to center: 0.05, Distance from start 31.59, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 50.28.\n",
      "Iteration 255.  State is <(0.30, -9.94), 5.7, 0.15>.  Distance to center: 0.05, Distance from start 31.71, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 50.48.\n",
      "Iteration 256.  State is <(0.42, -9.94), -0.3, 0.10>.  Distance to center: 0.05, Distance from start 31.84, Lidar 1.4, 3.0, 4.3, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 50.67.\n",
      "Iteration 257.  State is <(0.55, -9.93), 5.7, 0.15>.  Distance to center: 0.05, Distance from start 31.97, Lidar 1.5, 3.6, 5.2, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 50.87.\n",
      "Iteration 258.  State is <(0.67, -9.92), -0.3, 0.10>.  Distance to center: 0.05, Distance from start 32.09, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 51.07.\n",
      "Iteration 259.  State is <(0.80, -9.92), 5.7, 0.15>.  Distance to center: 0.05, Distance from start 32.22, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 51.27.\n",
      "Iteration 260.  State is <(0.92, -9.91), -0.3, 0.10>.  Distance to center: 0.05, Distance from start 32.34, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 51.47.\n",
      "Iteration 261.  State is <(1.04, -9.90), 5.7, 0.15>.  Distance to center: 0.04, Distance from start 32.47, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 51.67.\n",
      "Iteration 262.  State is <(1.17, -9.88), 11.7, 0.10>.  Distance to center: 0.05, Distance from start 32.59, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 51.87.\n",
      "Iteration 263.  State is <(1.29, -9.87), 5.7, 0.15>.  Distance to center: 0.05, Distance from start 32.72, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 52.07.\n",
      "Iteration 264.  State is <(1.42, -9.85), 11.7, 0.10>.  Distance to center: 0.05, Distance from start 32.84, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 52.27.\n",
      "Iteration 265.  State is <(1.54, -9.83), 5.7, 0.15>.  Distance to center: 0.05, Distance from start 32.97, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 52.47.\n",
      "Iteration 266.  State is <(1.66, -9.81), 11.7, 0.10>.  Distance to center: 0.05, Distance from start 33.09, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 52.67.\n",
      "Iteration 267.  State is <(1.79, -9.80), 5.7, 0.15>.  Distance to center: 0.04, Distance from start 33.22, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 52.87.\n",
      "Iteration 268.  State is <(1.91, -9.78), 11.7, 0.10>.  Distance to center: 0.04, Distance from start 33.34, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 53.07.\n",
      "Iteration 269.  State is <(2.03, -9.74), 17.7, 0.15>.  Distance to center: 0.05, Distance from start 33.47, Lidar 1.6, 4.0, 5.8, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 53.27.\n",
      "Iteration 270.  State is <(2.15, -9.71), 11.7, 0.10>.  Distance to center: 0.05, Distance from start 33.60, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 53.47.\n",
      "Iteration 271.  State is <(2.27, -9.68), 17.7, 0.15>.  Distance to center: 0.06, Distance from start 33.72, Lidar 1.5, 3.9, 5.6, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 53.67.\n",
      "Iteration 272.  State is <(2.39, -9.65), 11.7, 0.10>.  Distance to center: 0.06, Distance from start 33.85, Lidar 1.4, 3.1, 4.3, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 53.87.\n",
      "Iteration 273.  State is <(2.51, -9.61), 17.7, 0.15>.  Distance to center: 0.06, Distance from start 33.97, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.07.\n",
      "Iteration 274.  State is <(2.63, -9.58), 11.7, 0.10>.  Distance to center: 0.06, Distance from start 34.10, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 54.27.\n",
      "Iteration 275.  State is <(2.75, -9.55), 17.7, 0.15>.  Distance to center: 0.06, Distance from start 34.22, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.47.\n",
      "Iteration 276.  State is <(2.87, -9.51), 11.7, 0.10>.  Distance to center: 0.06, Distance from start 34.35, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 54.67.\n",
      "Iteration 277.  State is <(2.99, -9.48), 17.7, 0.15>.  Distance to center: 0.06, Distance from start 34.47, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.87.\n",
      "Iteration 278.  State is <(3.11, -9.45), 11.7, 0.10>.  Distance to center: 0.05, Distance from start 34.60, Lidar 1.3, 2.7, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 55.07.\n",
      "Iteration 279.  State is <(3.23, -9.42), 17.7, 0.15>.  Distance to center: 0.04, Distance from start 34.72, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 55.27.\n",
      "Iteration 280.  State is <(3.35, -9.37), 23.7, 0.10>.  Distance to center: 0.05, Distance from start 34.85, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 55.47.\n",
      "Iteration 281.  State is <(3.47, -9.33), 17.7, 0.15>.  Distance to center: 0.05, Distance from start 34.98, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 55.67.\n",
      "Iteration 282.  State is <(3.59, -9.29), 23.7, 0.10>.  Distance to center: 0.05, Distance from start 35.10, Lidar 1.5, 3.6, 5.2, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 55.87.\n",
      "Iteration 283.  State is <(3.70, -9.24), 17.7, 0.15>.  Distance to center: 0.04, Distance from start 35.23, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 56.06.\n",
      "Iteration 284.  State is <(3.82, -9.20), 23.7, 0.10>.  Distance to center: 0.04, Distance from start 35.35, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 56.26.\n",
      "Iteration 285.  State is <(3.94, -9.16), 17.7, 0.15>.  Distance to center: 0.03, Distance from start 35.48, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 56.46.\n",
      "Iteration 286.  State is <(4.05, -9.11), 23.7, 0.10>.  Distance to center: 0.02, Distance from start 35.60, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 56.66.\n",
      "Iteration 287.  State is <(4.17, -9.06), 29.7, 0.15>.  Distance to center: 0.03, Distance from start 35.73, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 56.86.\n",
      "Iteration 288.  State is <(4.28, -9.00), 23.7, 0.10>.  Distance to center: 0.04, Distance from start 35.85, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 57.06.\n",
      "Iteration 289.  State is <(4.39, -8.94), 29.7, 0.15>.  Distance to center: 0.04, Distance from start 35.98, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 57.26.\n",
      "Iteration 290.  State is <(4.50, -8.89), 23.7, 0.10>.  Distance to center: 0.04, Distance from start 36.10, Lidar 1.3, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 57.46.\n",
      "Iteration 291.  State is <(4.61, -8.83), 29.7, 0.15>.  Distance to center: 0.04, Distance from start 36.23, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 57.66.\n",
      "Iteration 292.  State is <(4.72, -8.77), 23.7, 0.10>.  Distance to center: 0.04, Distance from start 36.35, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 57.86.\n",
      "Iteration 293.  State is <(4.83, -8.71), 29.7, 0.15>.  Distance to center: 0.04, Distance from start 36.48, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 58.06.\n",
      "Iteration 294.  State is <(4.94, -8.65), 35.7, 0.10>.  Distance to center: 0.04, Distance from start 36.60, Lidar 1.6, 4.0, 5.8, 8.2, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 58.26.\n",
      "Iteration 295.  State is <(5.04, -8.58), 29.7, 0.15>.  Distance to center: 0.05, Distance from start 36.73, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 58.46.\n",
      "Iteration 296.  State is <(5.15, -8.51), 35.7, 0.10>.  Distance to center: 0.05, Distance from start 36.85, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 58.66.\n",
      "Iteration 297.  State is <(5.25, -8.45), 29.7, 0.15>.  Distance to center: 0.05, Distance from start 36.98, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 58.86.\n",
      "Iteration 298.  State is <(5.36, -8.38), 35.7, 0.10>.  Distance to center: 0.05, Distance from start 37.11, Lidar 1.5, 3.6, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.05.\n",
      "Iteration 299.  State is <(5.47, -8.32), 29.7, 0.15>.  Distance to center: 0.05, Distance from start 37.23, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 59.25.\n",
      "Iteration 300.  State is <(5.57, -8.25), 35.7, 0.10>.  Distance to center: 0.05, Distance from start 37.36, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.45.\n",
      "Iteration 301.  State is <(5.68, -8.18), 29.7, 0.15>.  Distance to center: 0.04, Distance from start 37.48, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 59.65.\n",
      "Iteration 302.  State is <(5.78, -8.12), 35.7, 0.10>.  Distance to center: 0.03, Distance from start 37.61, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.85.\n",
      "Iteration 303.  State is <(5.88, -8.04), 41.7, 0.15>.  Distance to center: 0.04, Distance from start 37.73, Lidar 1.5, 4.0, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 60.05.\n",
      "Iteration 304.  State is <(5.98, -7.96), 35.7, 0.10>.  Distance to center: 0.05, Distance from start 37.86, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 60.25.\n",
      "Iteration 305.  State is <(6.07, -7.88), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 37.98, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 60.45.\n",
      "Iteration 306.  State is <(6.17, -7.80), 35.7, 0.10>.  Distance to center: 0.06, Distance from start 38.11, Lidar 1.4, 3.0, 4.3, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 60.65.\n",
      "Iteration 307.  State is <(6.27, -7.72), 41.7, 0.15>.  Distance to center: 0.06, Distance from start 38.23, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 60.85.\n",
      "Iteration 308.  State is <(6.36, -7.64), 35.7, 0.10>.  Distance to center: 0.06, Distance from start 38.36, Lidar 1.4, 2.9, 4.1, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 61.05.\n",
      "Iteration 309.  State is <(6.46, -7.56), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 38.48, Lidar 1.5, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 61.25.\n",
      "Iteration 310.  State is <(6.56, -7.48), 35.7, 0.10>.  Distance to center: 0.05, Distance from start 38.61, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 61.45.\n",
      "Iteration 311.  State is <(6.65, -7.40), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 38.74, Lidar 1.4, 3.2, 4.6, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 61.65.\n",
      "Iteration 312.  State is <(6.74, -7.32), 47.7, 0.10>.  Distance to center: 0.05, Distance from start 38.86, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 61.85.\n",
      "Iteration 313.  State is <(6.83, -7.23), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 38.99, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 62.05.\n",
      "Iteration 314.  State is <(6.92, -7.14), 47.7, 0.10>.  Distance to center: 0.05, Distance from start 39.11, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 62.25.\n",
      "Iteration 315.  State is <(7.01, -7.06), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 39.24, Lidar 1.4, 3.0, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 62.45.\n",
      "Iteration 316.  State is <(7.10, -6.97), 47.7, 0.10>.  Distance to center: 0.05, Distance from start 39.36, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 62.65.\n",
      "Iteration 317.  State is <(7.19, -6.88), 41.7, 0.15>.  Distance to center: 0.05, Distance from start 39.49, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 62.85.\n",
      "Iteration 318.  State is <(7.28, -6.80), 47.7, 0.10>.  Distance to center: 0.04, Distance from start 39.61, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 63.05.\n",
      "Iteration 319.  State is <(7.37, -6.71), 41.7, 0.15>.  Distance to center: 0.03, Distance from start 39.74, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 63.25.\n",
      "Iteration 320.  State is <(7.46, -6.62), 47.7, 0.10>.  Distance to center: 0.03, Distance from start 39.86, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 63.44.\n",
      "Iteration 321.  State is <(7.54, -6.53), 53.7, 0.15>.  Distance to center: 0.03, Distance from start 39.99, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 63.64.\n",
      "Iteration 322.  State is <(7.61, -6.43), 47.7, 0.10>.  Distance to center: 0.03, Distance from start 40.11, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 63.84.\n",
      "Iteration 323.  State is <(7.69, -6.33), 53.7, 0.15>.  Distance to center: 0.04, Distance from start 40.24, Lidar 1.5, 3.6, 5.2, 7.5, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.04.\n",
      "Iteration 324.  State is <(7.77, -6.23), 47.7, 0.10>.  Distance to center: 0.04, Distance from start 40.36, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 64.24.\n",
      "Iteration 325.  State is <(7.85, -6.14), 53.7, 0.15>.  Distance to center: 0.04, Distance from start 40.49, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.44.\n",
      "Iteration 326.  State is <(7.93, -6.04), 47.7, 0.10>.  Distance to center: 0.04, Distance from start 40.61, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 64.64.\n",
      "Iteration 327.  State is <(8.01, -5.94), 53.7, 0.15>.  Distance to center: 0.03, Distance from start 40.74, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.84.\n",
      "Iteration 328.  State is <(8.07, -5.84), 59.7, 0.10>.  Distance to center: 0.04, Distance from start 40.86, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 65.04.\n",
      "Iteration 329.  State is <(8.14, -5.73), 53.7, 0.15>.  Distance to center: 0.04, Distance from start 40.99, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 65.24.\n",
      "Iteration 330.  State is <(8.21, -5.63), 59.7, 0.10>.  Distance to center: 0.04, Distance from start 41.12, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 65.44.\n",
      "Iteration 331.  State is <(8.28, -5.53), 53.7, 0.15>.  Distance to center: 0.04, Distance from start 41.24, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 65.64.\n",
      "Iteration 332.  State is <(8.35, -5.42), 59.7, 0.10>.  Distance to center: 0.04, Distance from start 41.37, Lidar 1.5, 3.6, 5.2, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 65.84.\n",
      "Iteration 333.  State is <(8.42, -5.32), 53.7, 0.15>.  Distance to center: 0.04, Distance from start 41.49, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 66.04.\n",
      "Iteration 334.  State is <(8.49, -5.22), 59.7, 0.10>.  Distance to center: 0.03, Distance from start 41.62, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 66.23.\n",
      "Iteration 335.  State is <(8.56, -5.11), 53.7, 0.15>.  Distance to center: 0.03, Distance from start 41.74, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 66.43.\n",
      "Iteration 336.  State is <(8.63, -5.01), 59.7, 0.10>.  Distance to center: 0.02, Distance from start 41.87, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 66.63.\n",
      "Iteration 337.  State is <(8.69, -4.90), 65.7, 0.15>.  Distance to center: 0.03, Distance from start 41.99, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 66.83.\n",
      "Iteration 338.  State is <(8.74, -4.78), 59.7, 0.10>.  Distance to center: 0.03, Distance from start 42.12, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 67.03.\n",
      "Iteration 339.  State is <(8.80, -4.67), 65.7, 0.15>.  Distance to center: 0.04, Distance from start 42.24, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 67.23.\n",
      "Iteration 340.  State is <(8.86, -4.56), 59.7, 0.10>.  Distance to center: 0.04, Distance from start 42.37, Lidar 1.3, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 67.43.\n",
      "Iteration 341.  State is <(8.91, -4.45), 65.7, 0.15>.  Distance to center: 0.04, Distance from start 42.49, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 67.63.\n",
      "Iteration 342.  State is <(8.97, -4.34), 59.7, 0.10>.  Distance to center: 0.04, Distance from start 42.62, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 67.83.\n",
      "Iteration 343.  State is <(9.02, -4.23), 65.7, 0.15>.  Distance to center: 0.04, Distance from start 42.74, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 68.03.\n",
      "Iteration 344.  State is <(9.07, -4.11), 71.7, 0.10>.  Distance to center: 0.04, Distance from start 42.87, Lidar 1.6, 4.0, 5.8, 8.2, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 68.23.\n",
      "Iteration 345.  State is <(9.12, -4.00), 65.7, 0.15>.  Distance to center: 0.05, Distance from start 42.99, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 68.43.\n",
      "Iteration 346.  State is <(9.16, -3.88), 71.7, 0.10>.  Distance to center: 0.05, Distance from start 43.12, Lidar 1.5, 3.9, 5.6, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 68.63.\n",
      "Iteration 347.  State is <(9.21, -3.76), 65.7, 0.15>.  Distance to center: 0.05, Distance from start 43.24, Lidar 1.4, 3.1, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 68.83.\n",
      "Iteration 348.  State is <(9.26, -3.65), 71.7, 0.10>.  Distance to center: 0.05, Distance from start 43.37, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.03.\n",
      "Iteration 349.  State is <(9.30, -3.53), 65.7, 0.15>.  Distance to center: 0.05, Distance from start 43.50, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 69.23.\n",
      "Iteration 350.  State is <(9.35, -3.42), 71.7, 0.10>.  Distance to center: 0.05, Distance from start 43.62, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.42.\n",
      "Iteration 351.  State is <(9.40, -3.30), 65.7, 0.15>.  Distance to center: 0.04, Distance from start 43.75, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 69.62.\n",
      "Iteration 352.  State is <(9.44, -3.18), 71.7, 0.10>.  Distance to center: 0.03, Distance from start 43.87, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.82.\n",
      "Iteration 353.  State is <(9.47, -3.06), 77.7, 0.15>.  Distance to center: 0.04, Distance from start 44.00, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 70.02.\n",
      "Iteration 354.  State is <(9.51, -2.94), 71.7, 0.10>.  Distance to center: 0.05, Distance from start 44.12, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 70.22.\n",
      "Iteration 355.  State is <(9.54, -2.82), 77.7, 0.15>.  Distance to center: 0.05, Distance from start 44.25, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 70.42.\n",
      "Iteration 356.  State is <(9.57, -2.70), 71.7, 0.10>.  Distance to center: 0.06, Distance from start 44.37, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 70.62.\n",
      "Iteration 357.  State is <(9.60, -2.58), 77.7, 0.15>.  Distance to center: 0.06, Distance from start 44.50, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 70.82.\n",
      "Iteration 358.  State is <(9.63, -2.46), 71.7, 0.10>.  Distance to center: 0.06, Distance from start 44.62, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 71.02.\n",
      "Iteration 359.  State is <(9.66, -2.34), 77.7, 0.15>.  Distance to center: 0.06, Distance from start 44.75, Lidar 1.5, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 71.22.\n",
      "Iteration 360.  State is <(9.70, -2.22), 71.7, 0.10>.  Distance to center: 0.05, Distance from start 44.87, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 71.42.\n",
      "Iteration 361.  State is <(9.73, -2.10), 77.7, 0.15>.  Distance to center: 0.05, Distance from start 45.00, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 71.62.\n",
      "Iteration 362.  State is <(9.75, -1.97), 83.7, 0.10>.  Distance to center: 0.05, Distance from start 45.13, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 71.82.\n",
      "Iteration 363.  State is <(9.77, -1.85), 77.7, 0.15>.  Distance to center: 0.06, Distance from start 45.25, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 72.02.\n",
      "Iteration 364.  State is <(9.79, -1.73), 83.7, 0.10>.  Distance to center: 0.06, Distance from start 45.38, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 72.22.\n",
      "Iteration 365.  State is <(9.81, -1.61), 77.7, 0.15>.  Distance to center: 0.06, Distance from start 45.50, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 72.42.\n",
      "Iteration 366.  State is <(9.83, -1.48), 83.7, 0.10>.  Distance to center: 0.05, Distance from start 45.63, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 72.62.\n",
      "Iteration 367.  State is <(9.86, -1.36), 77.7, 0.15>.  Distance to center: 0.05, Distance from start 45.75, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 72.82.\n",
      "Iteration 368.  State is <(9.88, -1.24), 83.7, 0.10>.  Distance to center: 0.05, Distance from start 45.88, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 73.02.\n",
      "Iteration 369.  State is <(9.90, -1.11), 77.7, 0.15>.  Distance to center: 0.04, Distance from start 46.00, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 73.22.\n",
      "Iteration 370.  State is <(9.92, -0.99), 83.7, 0.10>.  Distance to center: 0.03, Distance from start 46.13, Lidar 1.4, 3.2, 4.5, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 73.42.\n",
      "Iteration 371.  State is <(9.93, -0.87), 89.7, 0.15>.  Distance to center: 0.04, Distance from start 46.25, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 73.61.\n",
      "Iteration 372.  State is <(9.93, -0.74), 83.7, 0.10>.  Distance to center: 0.04, Distance from start 46.38, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 73.81.\n",
      "Iteration 373.  State is <(9.94, -0.62), 89.7, 0.15>.  Distance to center: 0.04, Distance from start 46.50, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.01.\n",
      "Iteration 374.  State is <(9.94, -0.49), 83.7, 0.10>.  Distance to center: 0.04, Distance from start 46.63, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 74.21.\n",
      "Iteration 375.  State is <(9.95, -0.37), 89.7, 0.15>.  Distance to center: 0.04, Distance from start 46.75, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.41.\n",
      "Iteration 376.  State is <(9.96, -0.24), 83.7, 0.10>.  Distance to center: 0.04, Distance from start 46.88, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 74.61.\n",
      "Iteration 377.  State is <(9.96, -0.12), 89.7, 0.15>.  Distance to center: 0.04, Distance from start 47.01, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.81.\n",
      "Iteration 378.  State is <(9.96, 0.01), 95.7, 0.10>.  Distance to center: 0.04, Distance from start 47.13, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 75.01.\n",
      "Iteration 379.  State is <(9.95, 0.13), 89.7, 0.15>.  Distance to center: 0.05, Distance from start 47.26, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 75.21.\n",
      "Iteration 380.  State is <(9.95, 0.26), 95.7, 0.10>.  Distance to center: 0.05, Distance from start 47.38, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 75.41.\n",
      "Iteration 381.  State is <(9.94, 0.38), 89.7, 0.15>.  Distance to center: 0.05, Distance from start 47.51, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 75.61.\n",
      "Iteration 382.  State is <(9.94, 0.51), 95.7, 0.10>.  Distance to center: 0.05, Distance from start 47.63, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 75.81.\n",
      "Iteration 383.  State is <(9.93, 0.63), 89.7, 0.15>.  Distance to center: 0.05, Distance from start 47.76, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 76.01.\n",
      "Iteration 384.  State is <(9.93, 0.76), 95.7, 0.10>.  Distance to center: 0.04, Distance from start 47.88, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 76.21.\n",
      "Iteration 385.  State is <(9.92, 0.88), 89.7, 0.15>.  Distance to center: 0.04, Distance from start 48.01, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 76.41.\n",
      "Iteration 386.  State is <(9.92, 1.00), 95.7, 0.10>.  Distance to center: 0.03, Distance from start 48.13, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 76.61.\n",
      "Iteration 387.  State is <(9.90, 1.13), 101.7, 0.15>.  Distance to center: 0.04, Distance from start 48.26, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 76.81.\n",
      "Iteration 388.  State is <(9.88, 1.25), 95.7, 0.10>.  Distance to center: 0.04, Distance from start 48.38, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 77.00.\n",
      "Iteration 389.  State is <(9.86, 1.37), 101.7, 0.15>.  Distance to center: 0.05, Distance from start 48.51, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 77.20.\n",
      "Iteration 390.  State is <(9.84, 1.50), 95.7, 0.10>.  Distance to center: 0.05, Distance from start 48.63, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 77.40.\n",
      "Iteration 391.  State is <(9.82, 1.62), 101.7, 0.15>.  Distance to center: 0.05, Distance from start 48.76, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 77.60.\n",
      "Iteration 392.  State is <(9.80, 1.74), 95.7, 0.10>.  Distance to center: 0.05, Distance from start 48.89, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 77.80.\n",
      "Iteration 393.  State is <(9.78, 1.87), 101.7, 0.15>.  Distance to center: 0.04, Distance from start 49.01, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 78.00.\n",
      "Iteration 394.  State is <(9.76, 1.99), 95.7, 0.10>.  Distance to center: 0.04, Distance from start 49.14, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 78.20.\n",
      "Iteration 395.  State is <(9.74, 2.11), 101.7, 0.15>.  Distance to center: 0.04, Distance from start 49.26, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 78.40.\n",
      "Iteration 396.  State is <(9.71, 2.23), 107.7, 0.10>.  Distance to center: 0.04, Distance from start 49.39, Lidar 1.5, 3.8, 5.6, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 78.60.\n",
      "Iteration 397.  State is <(9.68, 2.36), 101.7, 0.15>.  Distance to center: 0.04, Distance from start 49.51, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 78.80.\n",
      "Iteration 398.  State is <(9.65, 2.48), 107.7, 0.10>.  Distance to center: 0.04, Distance from start 49.64, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 79.00.\n",
      "Iteration 399.  State is <(9.62, 2.60), 101.7, 0.15>.  Distance to center: 0.04, Distance from start 49.76, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 79.20.\n",
      "Iteration 400.  State is <(9.59, 2.72), 107.7, 0.10>.  Distance to center: 0.04, Distance from start 49.89, Lidar 1.4, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 79.40.\n",
      "Iteration 401.  State is <(9.56, 2.84), 101.7, 0.15>.  Distance to center: 0.03, Distance from start 50.01, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 79.60.\n",
      "Iteration 402.  State is <(9.53, 2.96), 107.7, 0.10>.  Distance to center: 0.03, Distance from start 50.14, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 79.80.\n",
      "Iteration 403.  State is <(9.48, 3.08), 113.7, 0.15>.  Distance to center: 0.03, Distance from start 50.26, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 80.00.\n",
      "Iteration 404.  State is <(9.43, 3.19), 107.7, 0.10>.  Distance to center: 0.04, Distance from start 50.39, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 80.19.\n",
      "Iteration 405.  State is <(9.39, 3.31), 113.7, 0.15>.  Distance to center: 0.04, Distance from start 50.51, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 80.39.\n",
      "Iteration 406.  State is <(9.34, 3.43), 107.7, 0.10>.  Distance to center: 0.05, Distance from start 50.64, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 80.59.\n",
      "Iteration 407.  State is <(9.30, 3.54), 113.7, 0.15>.  Distance to center: 0.05, Distance from start 50.76, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 80.79.\n",
      "Iteration 408.  State is <(9.25, 3.66), 107.7, 0.10>.  Distance to center: 0.05, Distance from start 50.89, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 80.99.\n",
      "Iteration 409.  State is <(9.21, 3.78), 113.7, 0.15>.  Distance to center: 0.05, Distance from start 51.01, Lidar 1.4, 3.4, 4.9, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 81.19.\n",
      "Iteration 410.  State is <(9.16, 3.89), 107.7, 0.10>.  Distance to center: 0.05, Distance from start 51.14, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 81.39.\n",
      "Iteration 411.  State is <(9.12, 4.01), 113.7, 0.15>.  Distance to center: 0.04, Distance from start 51.27, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 81.59.\n",
      "Iteration 412.  State is <(9.06, 4.12), 119.7, 0.10>.  Distance to center: 0.05, Distance from start 51.39, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 81.79.\n",
      "Iteration 413.  State is <(9.01, 4.23), 113.7, 0.15>.  Distance to center: 0.05, Distance from start 51.52, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 81.99.\n",
      "Iteration 414.  State is <(8.95, 4.34), 119.7, 0.10>.  Distance to center: 0.05, Distance from start 51.64, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 82.19.\n",
      "Iteration 415.  State is <(8.90, 4.46), 113.7, 0.15>.  Distance to center: 0.05, Distance from start 51.77, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 82.39.\n",
      "Iteration 416.  State is <(8.84, 4.57), 119.7, 0.10>.  Distance to center: 0.05, Distance from start 51.89, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 82.59.\n",
      "Iteration 417.  State is <(8.79, 4.68), 113.7, 0.15>.  Distance to center: 0.04, Distance from start 52.02, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 82.79.\n",
      "Iteration 418.  State is <(8.73, 4.79), 119.7, 0.10>.  Distance to center: 0.04, Distance from start 52.14, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 82.99.\n",
      "Iteration 419.  State is <(8.68, 4.90), 113.7, 0.15>.  Distance to center: 0.03, Distance from start 52.27, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 83.19.\n",
      "Iteration 420.  State is <(8.62, 5.02), 119.7, 0.10>.  Distance to center: 0.02, Distance from start 52.39, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 83.39.\n",
      "Iteration 421.  State is <(8.55, 5.12), 125.7, 0.15>.  Distance to center: 0.03, Distance from start 52.52, Lidar 1.5, 3.8, 5.6, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 83.59.\n",
      "Iteration 422.  State is <(8.49, 5.23), 119.7, 0.10>.  Distance to center: 0.04, Distance from start 52.64, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 83.78.\n",
      "Iteration 423.  State is <(8.42, 5.33), 125.7, 0.15>.  Distance to center: 0.04, Distance from start 52.77, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 83.98.\n",
      "Iteration 424.  State is <(8.35, 5.43), 119.7, 0.10>.  Distance to center: 0.04, Distance from start 52.89, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 84.18.\n",
      "Iteration 425.  State is <(8.28, 5.54), 125.7, 0.15>.  Distance to center: 0.04, Distance from start 53.02, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 84.38.\n",
      "Iteration 426.  State is <(8.21, 5.64), 119.7, 0.10>.  Distance to center: 0.04, Distance from start 53.14, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 84.58.\n",
      "Iteration 427.  State is <(8.14, 5.75), 125.7, 0.15>.  Distance to center: 0.03, Distance from start 53.27, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 84.78.\n",
      "Iteration 428.  State is <(8.07, 5.84), 131.7, 0.10>.  Distance to center: 0.04, Distance from start 53.40, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 84.98.\n",
      "Iteration 429.  State is <(7.99, 5.94), 125.7, 0.15>.  Distance to center: 0.04, Distance from start 53.52, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 85.18.\n",
      "Iteration 430.  State is <(7.91, 6.04), 131.7, 0.10>.  Distance to center: 0.05, Distance from start 53.65, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 85.38.\n",
      "Iteration 431.  State is <(7.83, 6.14), 125.7, 0.15>.  Distance to center: 0.05, Distance from start 53.77, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 85.58.\n",
      "Iteration 432.  State is <(7.76, 6.24), 131.7, 0.10>.  Distance to center: 0.05, Distance from start 53.90, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 85.78.\n",
      "Iteration 433.  State is <(7.68, 6.34), 125.7, 0.15>.  Distance to center: 0.04, Distance from start 54.02, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 85.98.\n",
      "Iteration 434.  State is <(7.60, 6.43), 131.7, 0.10>.  Distance to center: 0.04, Distance from start 54.15, Lidar 1.4, 3.4, 4.9, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 86.18.\n",
      "Iteration 435.  State is <(7.53, 6.53), 125.7, 0.15>.  Distance to center: 0.03, Distance from start 54.27, Lidar 1.3, 2.7, 3.8, 5.6, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 86.38.\n",
      "Iteration 436.  State is <(7.45, 6.63), 131.7, 0.10>.  Distance to center: 0.03, Distance from start 54.40, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 86.58.\n",
      "Iteration 437.  State is <(7.36, 6.72), 137.7, 0.15>.  Distance to center: 0.03, Distance from start 54.52, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 86.78.\n",
      "Iteration 438.  State is <(7.27, 6.81), 131.7, 0.10>.  Distance to center: 0.04, Distance from start 54.65, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 86.97.\n",
      "Iteration 439.  State is <(7.18, 6.89), 137.7, 0.15>.  Distance to center: 0.04, Distance from start 54.77, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.17.\n",
      "Iteration 440.  State is <(7.09, 6.98), 131.7, 0.10>.  Distance to center: 0.05, Distance from start 54.90, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 87.37.\n",
      "Iteration 441.  State is <(7.00, 7.07), 137.7, 0.15>.  Distance to center: 0.05, Distance from start 55.02, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.57.\n",
      "Iteration 442.  State is <(6.92, 7.16), 131.7, 0.10>.  Distance to center: 0.05, Distance from start 55.15, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 87.77.\n",
      "Iteration 443.  State is <(6.83, 7.25), 137.7, 0.15>.  Distance to center: 0.04, Distance from start 55.27, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.97.\n",
      "Iteration 444.  State is <(6.74, 7.33), 131.7, 0.10>.  Distance to center: 0.04, Distance from start 55.40, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 88.17.\n",
      "Iteration 445.  State is <(6.65, 7.42), 137.7, 0.15>.  Distance to center: 0.04, Distance from start 55.53, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 88.37.\n",
      "Iteration 446.  State is <(6.55, 7.50), 143.7, 0.10>.  Distance to center: 0.04, Distance from start 55.65, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 88.57.\n",
      "Iteration 447.  State is <(6.46, 7.58), 137.7, 0.15>.  Distance to center: 0.04, Distance from start 55.78, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 88.77.\n",
      "Iteration 448.  State is <(6.36, 7.66), 143.7, 0.10>.  Distance to center: 0.04, Distance from start 55.90, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 88.97.\n",
      "Iteration 449.  State is <(6.27, 7.74), 137.7, 0.15>.  Distance to center: 0.04, Distance from start 56.03, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 89.17.\n",
      "Iteration 450.  State is <(6.17, 7.82), 143.7, 0.10>.  Distance to center: 0.04, Distance from start 56.15, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 89.37.\n",
      "Iteration 451.  State is <(6.08, 7.90), 137.7, 0.15>.  Distance to center: 0.03, Distance from start 56.28, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 89.57.\n",
      "Iteration 452.  State is <(5.98, 7.98), 143.7, 0.10>.  Distance to center: 0.03, Distance from start 56.40, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 89.77.\n",
      "Iteration 453.  State is <(5.87, 8.05), 149.7, 0.15>.  Distance to center: 0.04, Distance from start 56.53, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 89.97.\n",
      "Iteration 454.  State is <(5.77, 8.12), 143.7, 0.10>.  Distance to center: 0.04, Distance from start 56.65, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 90.16.\n",
      "Iteration 455.  State is <(5.66, 8.18), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 56.78, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 90.36.\n",
      "Iteration 456.  State is <(5.56, 8.25), 143.7, 0.10>.  Distance to center: 0.05, Distance from start 56.90, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 90.56.\n",
      "Iteration 457.  State is <(5.45, 8.32), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 57.03, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 90.76.\n",
      "Iteration 458.  State is <(5.35, 8.39), 143.7, 0.10>.  Distance to center: 0.05, Distance from start 57.15, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 90.96.\n",
      "Iteration 459.  State is <(5.24, 8.45), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 57.28, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 91.16.\n",
      "Iteration 460.  State is <(5.14, 8.52), 143.7, 0.10>.  Distance to center: 0.05, Distance from start 57.40, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 91.36.\n",
      "Iteration 461.  State is <(5.03, 8.59), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 57.53, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 91.56.\n",
      "Iteration 462.  State is <(4.92, 8.65), 155.7, 0.10>.  Distance to center: 0.05, Distance from start 57.66, Lidar 1.5, 4.0, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 91.76.\n",
      "Iteration 463.  State is <(4.81, 8.70), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 57.78, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 91.96.\n",
      "Iteration 464.  State is <(4.70, 8.76), 155.7, 0.10>.  Distance to center: 0.05, Distance from start 57.91, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.16.\n",
      "Iteration 465.  State is <(4.59, 8.82), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 58.03, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 92.36.\n",
      "Iteration 466.  State is <(4.48, 8.88), 155.7, 0.10>.  Distance to center: 0.05, Distance from start 58.16, Lidar 1.5, 3.6, 5.1, 7.3, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.56.\n",
      "Iteration 467.  State is <(4.37, 8.94), 149.7, 0.15>.  Distance to center: 0.05, Distance from start 58.28, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 92.76.\n",
      "Iteration 468.  State is <(4.26, 9.00), 155.7, 0.10>.  Distance to center: 0.05, Distance from start 58.41, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.96.\n",
      "Iteration 469.  State is <(4.15, 9.06), 149.7, 0.15>.  Distance to center: 0.04, Distance from start 58.53, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 93.16.\n",
      "Iteration 470.  State is <(4.04, 9.11), 155.7, 0.10>.  Distance to center: 0.03, Distance from start 58.66, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 93.36.\n",
      "Iteration 471.  State is <(3.92, 9.16), 161.7, 0.15>.  Distance to center: 0.04, Distance from start 58.78, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 93.56.\n",
      "Iteration 472.  State is <(3.81, 9.20), 155.7, 0.10>.  Distance to center: 0.04, Distance from start 58.91, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 93.76.\n",
      "Iteration 473.  State is <(3.69, 9.25), 161.7, 0.15>.  Distance to center: 0.05, Distance from start 59.03, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 93.96.\n",
      "Iteration 474.  State is <(3.57, 9.29), 155.7, 0.10>.  Distance to center: 0.05, Distance from start 59.16, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.16.\n",
      "Iteration 475.  State is <(3.46, 9.33), 161.7, 0.15>.  Distance to center: 0.05, Distance from start 59.28, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 94.35.\n",
      "Iteration 476.  State is <(3.34, 9.38), 155.7, 0.10>.  Distance to center: 0.04, Distance from start 59.41, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.55.\n",
      "Iteration 477.  State is <(3.22, 9.42), 161.7, 0.15>.  Distance to center: 0.04, Distance from start 59.54, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 94.75.\n",
      "Iteration 478.  State is <(3.11, 9.47), 155.7, 0.10>.  Distance to center: 0.04, Distance from start 59.66, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.95.\n",
      "Iteration 479.  State is <(2.99, 9.51), 161.7, 0.15>.  Distance to center: 0.03, Distance from start 59.79, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 95.15.\n",
      "Iteration 480.  State is <(2.87, 9.54), 167.7, 0.10>.  Distance to center: 0.03, Distance from start 59.91, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 95.35.\n",
      "Iteration 481.  State is <(2.75, 9.58), 161.7, 0.15>.  Distance to center: 0.03, Distance from start 60.04, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 95.55.\n",
      "Iteration 482.  State is <(2.63, 9.61), 167.7, 0.10>.  Distance to center: 0.03, Distance from start 60.16, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 95.75.\n",
      "Iteration 483.  State is <(2.51, 9.65), 161.7, 0.15>.  Distance to center: 0.03, Distance from start 60.29, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 95.95.\n",
      "Iteration 484.  State is <(2.39, 9.68), 167.7, 0.10>.  Distance to center: 0.03, Distance from start 60.41, Lidar 1.4, 3.4, 4.9, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 96.15.\n",
      "Iteration 485.  State is <(2.27, 9.72), 161.7, 0.15>.  Distance to center: 0.02, Distance from start 60.54, Lidar 1.3, 2.7, 3.8, 5.6, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 96.35.\n",
      "Iteration 486.  State is <(2.15, 9.75), 167.7, 0.10>.  Distance to center: 0.02, Distance from start 60.66, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 96.55.\n",
      "Iteration 487.  State is <(2.03, 9.77), 173.7, 0.15>.  Distance to center: 0.02, Distance from start 60.79, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 96.75.\n",
      "Iteration 488.  State is <(1.90, 9.79), 167.7, 0.10>.  Distance to center: 0.03, Distance from start 60.91, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 96.94.\n",
      "Iteration 489.  State is <(1.78, 9.81), 173.7, 0.15>.  Distance to center: 0.03, Distance from start 61.04, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.14.\n",
      "Iteration 490.  State is <(1.66, 9.82), 167.7, 0.10>.  Distance to center: 0.04, Distance from start 61.16, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 97.34.\n",
      "Iteration 491.  State is <(1.53, 9.84), 173.7, 0.15>.  Distance to center: 0.04, Distance from start 61.29, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.54.\n",
      "Iteration 492.  State is <(1.41, 9.86), 167.7, 0.10>.  Distance to center: 0.04, Distance from start 61.41, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 97.74.\n",
      "Iteration 493.  State is <(1.29, 9.88), 173.7, 0.15>.  Distance to center: 0.04, Distance from start 61.54, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.94.\n",
      "Iteration 494.  State is <(1.16, 9.90), 167.7, 0.10>.  Distance to center: 0.03, Distance from start 61.66, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 98.14.\n",
      "Iteration 495.  State is <(1.04, 9.92), 173.7, 0.15>.  Distance to center: 0.03, Distance from start 61.79, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 98.34.\n",
      "Iteration 496.  State is <(0.91, 9.93), 179.7, 0.10>.  Distance to center: 0.03, Distance from start 61.91, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 98.54.\n",
      "Iteration 497.  State is <(0.79, 9.94), 173.7, 0.15>.  Distance to center: 0.03, Distance from start 62.04, Lidar 1.4, 3.0, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 98.74.\n",
      "Iteration 498.  State is <(0.66, 9.94), 179.7, 0.10>.  Distance to center: 0.03, Distance from start 62.16, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 98.94.\n",
      "Iteration 499.  State is <(0.54, 9.95), 173.7, 0.15>.  Distance to center: 0.03, Distance from start 62.29, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 99.14.\n",
      "Iteration 500.  State is <(0.42, 9.96), 179.7, 0.10>.  Distance to center: 0.03, Distance from start 62.41, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 99.34.\n",
      "Iteration 501.  State is <(0.29, 9.97), 173.7, 0.15>.  Distance to center: 0.03, Distance from start 62.54, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 99.54.\n",
      "Iteration 502.  State is <(0.17, 9.98), 179.7, 0.10>.  Distance to center: 0.02, Distance from start 62.66, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 99.73.\n",
      "Iteration 503.  State is <(0.04, 9.97), 185.7, 0.15>.  Distance to center: 0.03, Distance from start 62.79, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 99.93.\n",
      "Iteration 504.  State is <(-0.08, 9.96), 179.7, 0.10>.  Distance to center: 0.04, Distance from start 0.08, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 15.13 and totalReward 115.06.\n",
      "\n",
      "Average speed = 0.125\n",
      "Maximum speed = 0.150\n",
      "Final score = 115.06212125658996\n",
      "Close canvas windows to end program.\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
