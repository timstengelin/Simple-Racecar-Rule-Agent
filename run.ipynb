{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac6664b",
   "metadata": {},
   "source": [
    "# Run Program from Jupyter Notebook\n",
    "This notebook runs the Python program with arguments directly inside Jupyter."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Get project from GitHub\n",
    "\n",
    "When working in Google Colab, use this to clone project."
   ],
   "id": "67cbd08e660fffe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Go back to the top-level\n",
    "%cd /content\n",
    "\n",
    "# Delete folder (if it already exists)\n",
    "!rm -rf Simple-Racecar-Rule-Agent\n",
    "\n",
    "# Clone the repo (again)\n",
    "!git clone https://github.com/timstengelin/Simple-Racecar-Rule-Agent.git\n",
    "%cd Simple-Racecar-Rule-Agent"
   ],
   "id": "dde03f9101091d4"
  },
  {
   "cell_type": "markdown",
   "id": "387198c8",
   "metadata": {},
   "source": [
    "## Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "id": "912c2347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T04:02:22.039670Z",
     "start_time": "2025-09-08T04:02:22.014106Z"
    }
   },
   "source": [
    "program_args = ['python3', 'Run.py', 'RuleAgent.py', '1']\n",
    "print('Current arguments:', program_args)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current arguments: ['python3', 'Run.py', 'RuleAgent.py', '1']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "71f97946",
   "metadata": {},
   "source": [
    "## Run using `!` (shell command)\n",
    "The arguments are joined into a single command."
   ]
  },
  {
   "cell_type": "code",
   "id": "43b96cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T04:02:27.126155Z",
     "start_time": "2025-09-08T04:02:26.455863Z"
    }
   },
   "source": [
    "command = ' '.join(program_args)\n",
    "print('Running:', command)\n",
    "!{command}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python3 Run.py RuleAgent.py 1\n",
      "Starting simulation\n",
      "Iteration 1.  State is <(-0.02, 10.14), 151.6, 0.05>.  Distance to center: 0.14, Distance from start 0.02, Lidar 0.9, 1.3, 1.6, 2.1, 8.0, Velocity 0.05, Choosing action ('right', 'accelerate'), reward 0.03 and totalReward 0.03.\n",
      "Iteration 2.  State is <(-0.09, 10.17), 157.6, 0.10>.  Distance to center: 0.17, Distance from start 0.09, Lidar 0.89, 1.4, 1.8, 2.5, 9.5, Velocity 0.10, Choosing action ('right', 'accelerate'), reward 0.11 and totalReward 0.14.\n",
      "Iteration 3.  State is <(-0.21, 10.21), 163.6, 0.15>.  Distance to center: 0.21, Distance from start 0.20, Lidar 0.88, 1.5, 2.0, 3.0, 1.1e+01, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.18 and totalReward 0.32.\n",
      "Iteration 4.  State is <(-0.33, 10.24), 169.6, 0.10>.  Distance to center: 0.24, Distance from start 0.32, Lidar 0.89, 1.7, 2.4, 3.6, 2.9, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.19 and totalReward 0.51.\n",
      "Iteration 5.  State is <(-0.45, 10.25), 175.6, 0.15>.  Distance to center: 0.26, Distance from start 0.44, Lidar 0.92, 2.0, 2.9, 4.5, 2.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 0.70.\n",
      "Iteration 6.  State is <(-0.58, 10.26), 181.6, 0.10>.  Distance to center: 0.27, Distance from start 0.56, Lidar 0.97, 2.4, 3.6, 5.7, 2.0, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.19 and totalReward 0.90.\n",
      "Iteration 7.  State is <(-0.70, 10.25), 187.6, 0.15>.  Distance to center: 0.27, Distance from start 0.68, Lidar 1.1, 3.0, 4.6, 7.0, 1.8, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 1.09.\n",
      "Iteration 8.  State is <(-0.83, 10.22), 193.6, 0.10>.  Distance to center: 0.26, Distance from start 0.81, Lidar 1.2, 3.8, 5.9, 8.5, 1.6, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.19 and totalReward 1.28.\n",
      "Iteration 9.  State is <(-0.94, 10.19), 199.6, 0.15>.  Distance to center: 0.23, Distance from start 0.92, Lidar 1.4, 4.9, 7.3, 1e+01, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 1.47.\n",
      "Iteration 10.  State is <(-1.06, 10.14), 205.6, 0.10>.  Distance to center: 0.20, Distance from start 1.04, Lidar 1.6, 6.2, 8.8, 3.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.19 and totalReward 1.66.\n",
      "Iteration 11.  State is <(-1.18, 10.09), 199.6, 0.15>.  Distance to center: 0.16, Distance from start 1.16, Lidar 1.4, 4.8, 7.1, 9.7, 1.4, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.19 and totalReward 1.85.\n",
      "Iteration 12.  State is <(-1.30, 10.06), 193.6, 0.10>.  Distance to center: 0.14, Distance from start 1.28, Lidar 1.3, 3.6, 5.5, 8.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.19 and totalReward 2.04.\n",
      "Iteration 13.  State is <(-1.41, 10.02), 199.6, 0.15>.  Distance to center: 0.12, Distance from start 1.40, Lidar 1.5, 4.6, 6.8, 9.4, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 2.23.\n",
      "Iteration 14.  State is <(-1.53, 9.98), 193.6, 0.10>.  Distance to center: 0.10, Distance from start 1.52, Lidar 1.3, 3.5, 5.3, 7.6, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.19 and totalReward 2.43.\n",
      "Iteration 15.  State is <(-1.65, 9.95), 199.6, 0.15>.  Distance to center: 0.08, Distance from start 1.65, Lidar 1.5, 4.4, 6.5, 9.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.19 and totalReward 2.62.\n",
      "Iteration 16.  State is <(-1.77, 9.91), 193.6, 0.10>.  Distance to center: 0.07, Distance from start 1.77, Lidar 1.3, 3.4, 5.1, 7.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 2.82.\n",
      "Iteration 17.  State is <(-1.89, 9.87), 199.6, 0.15>.  Distance to center: 0.05, Distance from start 1.89, Lidar 1.5, 4.2, 6.2, 8.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.01.\n",
      "Iteration 18.  State is <(-2.01, 9.84), 193.6, 0.10>.  Distance to center: 0.04, Distance from start 2.02, Lidar 1.3, 3.3, 4.9, 7.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 3.21.\n",
      "Iteration 19.  State is <(-2.13, 9.80), 199.6, 0.15>.  Distance to center: 0.03, Distance from start 2.14, Lidar 1.5, 4.1, 6.0, 8.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.41.\n",
      "Iteration 20.  State is <(-2.25, 9.76), 193.6, 0.10>.  Distance to center: 0.02, Distance from start 2.26, Lidar 1.3, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 3.60.\n",
      "Iteration 21.  State is <(-2.37, 9.73), 199.6, 0.15>.  Distance to center: 0.01, Distance from start 2.39, Lidar 1.5, 3.9, 5.7, 8.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 3.80.\n",
      "Iteration 22.  State is <(-2.49, 9.69), 193.6, 0.10>.  Distance to center: 0.00, Distance from start 2.51, Lidar 1.3, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 4.00.\n",
      "Iteration 23.  State is <(-2.61, 9.65), 199.6, 0.15>.  Distance to center: 0.00, Distance from start 2.64, Lidar 1.5, 3.7, 5.4, 7.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 4.20.\n",
      "Iteration 24.  State is <(-2.73, 9.62), 193.6, 0.10>.  Distance to center: 0.01, Distance from start 2.76, Lidar 1.3, 2.9, 4.2, 6.1, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 4.40.\n",
      "Iteration 25.  State is <(-2.85, 9.58), 199.6, 0.15>.  Distance to center: 0.01, Distance from start 2.89, Lidar 1.4, 3.5, 5.2, 7.4, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 4.60.\n",
      "Iteration 26.  State is <(-2.97, 9.54), 193.6, 0.10>.  Distance to center: 0.01, Distance from start 3.01, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 4.80.\n",
      "Iteration 27.  State is <(-3.08, 9.50), 199.6, 0.15>.  Distance to center: 0.01, Distance from start 3.14, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 4.99.\n",
      "Iteration 28.  State is <(-3.20, 9.46), 205.6, 0.10>.  Distance to center: 0.01, Distance from start 3.26, Lidar 1.5, 4.1, 6.0, 8.3, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.19.\n",
      "Iteration 29.  State is <(-3.32, 9.41), 199.6, 0.15>.  Distance to center: 0.02, Distance from start 3.39, Lidar 1.4, 3.2, 4.7, 6.7, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 5.39.\n",
      "Iteration 30.  State is <(-3.43, 9.36), 205.6, 0.10>.  Distance to center: 0.03, Distance from start 3.51, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.59.\n",
      "Iteration 31.  State is <(-3.55, 9.32), 199.6, 0.15>.  Distance to center: 0.03, Distance from start 3.64, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 5.79.\n",
      "Iteration 32.  State is <(-3.66, 9.27), 205.6, 0.10>.  Distance to center: 0.03, Distance from start 3.76, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 5.99.\n",
      "Iteration 33.  State is <(-3.78, 9.22), 199.6, 0.15>.  Distance to center: 0.03, Distance from start 3.89, Lidar 1.3, 2.9, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 6.19.\n",
      "Iteration 34.  State is <(-3.90, 9.18), 205.6, 0.10>.  Distance to center: 0.03, Distance from start 4.01, Lidar 1.4, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 6.39.\n",
      "Iteration 35.  State is <(-4.01, 9.13), 199.6, 0.15>.  Distance to center: 0.03, Distance from start 4.14, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 6.59.\n",
      "Iteration 36.  State is <(-4.13, 9.08), 205.6, 0.10>.  Distance to center: 0.02, Distance from start 4.26, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 6.79.\n",
      "Iteration 37.  State is <(-4.24, 9.02), 211.6, 0.15>.  Distance to center: 0.03, Distance from start 4.39, Lidar 1.5, 4.1, 5.9, 8.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 6.98.\n",
      "Iteration 38.  State is <(-4.34, 8.96), 205.6, 0.10>.  Distance to center: 0.04, Distance from start 4.51, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.18.\n",
      "Iteration 39.  State is <(-4.45, 8.90), 211.6, 0.15>.  Distance to center: 0.05, Distance from start 4.64, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 7.38.\n",
      "Iteration 40.  State is <(-4.56, 8.84), 205.6, 0.10>.  Distance to center: 0.05, Distance from start 4.76, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.58.\n",
      "Iteration 41.  State is <(-4.67, 8.78), 211.6, 0.15>.  Distance to center: 0.05, Distance from start 4.89, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 7.78.\n",
      "Iteration 42.  State is <(-4.78, 8.72), 205.6, 0.10>.  Distance to center: 0.06, Distance from start 5.02, Lidar 1.4, 3.0, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 7.98.\n",
      "Iteration 43.  State is <(-4.89, 8.66), 211.6, 0.15>.  Distance to center: 0.06, Distance from start 5.14, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 8.18.\n",
      "Iteration 44.  State is <(-5.00, 8.60), 205.6, 0.10>.  Distance to center: 0.05, Distance from start 5.27, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 8.38.\n",
      "Iteration 45.  State is <(-5.11, 8.54), 211.6, 0.15>.  Distance to center: 0.05, Distance from start 5.39, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 8.58.\n",
      "Iteration 46.  State is <(-5.22, 8.48), 205.6, 0.10>.  Distance to center: 0.05, Distance from start 5.52, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 8.78.\n",
      "Iteration 47.  State is <(-5.33, 8.42), 211.6, 0.15>.  Distance to center: 0.04, Distance from start 5.64, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 8.98.\n",
      "Iteration 48.  State is <(-5.43, 8.35), 217.6, 0.10>.  Distance to center: 0.04, Distance from start 5.77, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 9.18.\n",
      "Iteration 49.  State is <(-5.53, 8.28), 211.6, 0.15>.  Distance to center: 0.04, Distance from start 5.89, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 9.38.\n",
      "Iteration 50.  State is <(-5.64, 8.21), 217.6, 0.10>.  Distance to center: 0.04, Distance from start 6.02, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 9.58.\n",
      "Iteration 51.  State is <(-5.74, 8.14), 211.6, 0.15>.  Distance to center: 0.04, Distance from start 6.14, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 9.78.\n",
      "Iteration 52.  State is <(-5.84, 8.07), 217.6, 0.10>.  Distance to center: 0.04, Distance from start 6.27, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 9.98.\n",
      "Iteration 53.  State is <(-5.95, 8.00), 211.6, 0.15>.  Distance to center: 0.03, Distance from start 6.39, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 10.18.\n",
      "Iteration 54.  State is <(-6.05, 7.93), 217.6, 0.10>.  Distance to center: 0.03, Distance from start 6.52, Lidar 1.4, 3.2, 4.7, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 10.38.\n",
      "Iteration 55.  State is <(-6.14, 7.85), 223.6, 0.15>.  Distance to center: 0.03, Distance from start 6.64, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 10.57.\n",
      "Iteration 56.  State is <(-6.24, 7.76), 217.6, 0.10>.  Distance to center: 0.04, Distance from start 6.77, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 10.77.\n",
      "Iteration 57.  State is <(-6.33, 7.68), 223.6, 0.15>.  Distance to center: 0.05, Distance from start 6.89, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 10.97.\n",
      "Iteration 58.  State is <(-6.43, 7.60), 217.6, 0.10>.  Distance to center: 0.05, Distance from start 7.02, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 11.17.\n",
      "Iteration 59.  State is <(-6.52, 7.52), 223.6, 0.15>.  Distance to center: 0.05, Distance from start 7.15, Lidar 1.5, 3.6, 5.2, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 11.37.\n",
      "Iteration 60.  State is <(-6.61, 7.43), 217.6, 0.10>.  Distance to center: 0.05, Distance from start 7.27, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 11.57.\n",
      "Iteration 61.  State is <(-6.71, 7.35), 223.6, 0.15>.  Distance to center: 0.05, Distance from start 7.40, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 11.77.\n",
      "Iteration 62.  State is <(-6.80, 7.27), 217.6, 0.10>.  Distance to center: 0.04, Distance from start 7.52, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 11.97.\n",
      "Iteration 63.  State is <(-6.90, 7.19), 223.6, 0.15>.  Distance to center: 0.04, Distance from start 7.65, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 12.17.\n",
      "Iteration 64.  State is <(-6.98, 7.10), 229.6, 0.10>.  Distance to center: 0.04, Distance from start 7.77, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 12.37.\n",
      "Iteration 65.  State is <(-7.07, 7.01), 223.6, 0.15>.  Distance to center: 0.04, Distance from start 7.90, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 12.57.\n",
      "Iteration 66.  State is <(-7.16, 6.92), 229.6, 0.10>.  Distance to center: 0.05, Distance from start 8.02, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 12.77.\n",
      "Iteration 67.  State is <(-7.24, 6.83), 223.6, 0.15>.  Distance to center: 0.04, Distance from start 8.15, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 12.97.\n",
      "Iteration 68.  State is <(-7.33, 6.74), 229.6, 0.10>.  Distance to center: 0.04, Distance from start 8.27, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 13.17.\n",
      "Iteration 69.  State is <(-7.42, 6.65), 223.6, 0.15>.  Distance to center: 0.04, Distance from start 8.40, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 13.37.\n",
      "Iteration 70.  State is <(-7.50, 6.56), 229.6, 0.10>.  Distance to center: 0.03, Distance from start 8.52, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 13.57.\n",
      "Iteration 71.  State is <(-7.58, 6.46), 235.6, 0.15>.  Distance to center: 0.04, Distance from start 8.65, Lidar 1.5, 4.0, 5.8, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 13.77.\n",
      "Iteration 72.  State is <(-7.65, 6.36), 229.6, 0.10>.  Distance to center: 0.05, Distance from start 8.77, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 13.97.\n",
      "Iteration 73.  State is <(-7.73, 6.26), 235.6, 0.15>.  Distance to center: 0.05, Distance from start 8.90, Lidar 1.5, 3.9, 5.6, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.16.\n",
      "Iteration 74.  State is <(-7.80, 6.16), 229.6, 0.10>.  Distance to center: 0.06, Distance from start 9.03, Lidar 1.4, 3.1, 4.3, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 14.36.\n",
      "Iteration 75.  State is <(-7.88, 6.06), 235.6, 0.15>.  Distance to center: 0.06, Distance from start 9.15, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.56.\n",
      "Iteration 76.  State is <(-7.95, 5.96), 229.6, 0.10>.  Distance to center: 0.06, Distance from start 9.28, Lidar 1.4, 2.9, 4.1, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 14.76.\n",
      "Iteration 77.  State is <(-8.03, 5.86), 235.6, 0.15>.  Distance to center: 0.06, Distance from start 9.40, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 14.96.\n",
      "Iteration 78.  State is <(-8.10, 5.76), 229.6, 0.10>.  Distance to center: 0.06, Distance from start 9.53, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 15.16.\n",
      "Iteration 79.  State is <(-8.18, 5.66), 235.6, 0.15>.  Distance to center: 0.05, Distance from start 9.65, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 15.36.\n",
      "Iteration 80.  State is <(-8.25, 5.56), 229.6, 0.10>.  Distance to center: 0.05, Distance from start 9.78, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 15.56.\n",
      "Iteration 81.  State is <(-8.33, 5.46), 235.6, 0.15>.  Distance to center: 0.04, Distance from start 9.90, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 15.76.\n",
      "Iteration 82.  State is <(-8.39, 5.36), 241.6, 0.10>.  Distance to center: 0.04, Distance from start 10.03, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 15.96.\n",
      "Iteration 83.  State is <(-8.46, 5.25), 235.6, 0.15>.  Distance to center: 0.04, Distance from start 10.15, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 16.16.\n",
      "Iteration 84.  State is <(-8.53, 5.14), 241.6, 0.10>.  Distance to center: 0.04, Distance from start 10.28, Lidar 1.5, 3.6, 5.2, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 16.36.\n",
      "Iteration 85.  State is <(-8.59, 5.04), 235.6, 0.15>.  Distance to center: 0.04, Distance from start 10.41, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 16.56.\n",
      "Iteration 86.  State is <(-8.66, 4.93), 241.6, 0.10>.  Distance to center: 0.04, Distance from start 10.53, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 16.76.\n",
      "Iteration 87.  State is <(-8.72, 4.83), 235.6, 0.15>.  Distance to center: 0.03, Distance from start 10.66, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 16.96.\n",
      "Iteration 88.  State is <(-8.79, 4.72), 241.6, 0.10>.  Distance to center: 0.02, Distance from start 10.78, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 17.16.\n",
      "Iteration 89.  State is <(-8.84, 4.61), 247.6, 0.15>.  Distance to center: 0.03, Distance from start 10.91, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 17.36.\n",
      "Iteration 90.  State is <(-8.90, 4.49), 241.6, 0.10>.  Distance to center: 0.03, Distance from start 11.03, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 17.56.\n",
      "Iteration 91.  State is <(-8.95, 4.38), 247.6, 0.15>.  Distance to center: 0.04, Distance from start 11.16, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 17.75.\n",
      "Iteration 92.  State is <(-9.00, 4.27), 241.6, 0.10>.  Distance to center: 0.04, Distance from start 11.28, Lidar 1.3, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 17.95.\n",
      "Iteration 93.  State is <(-9.05, 4.15), 247.6, 0.15>.  Distance to center: 0.04, Distance from start 11.41, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 18.15.\n",
      "Iteration 94.  State is <(-9.11, 4.04), 241.6, 0.10>.  Distance to center: 0.04, Distance from start 11.53, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 18.35.\n",
      "Iteration 95.  State is <(-9.16, 3.93), 247.6, 0.15>.  Distance to center: 0.04, Distance from start 11.66, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 18.55.\n",
      "Iteration 96.  State is <(-9.20, 3.81), 253.6, 0.10>.  Distance to center: 0.04, Distance from start 11.78, Lidar 1.6, 4.0, 5.8, 8.2, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 18.75.\n",
      "Iteration 97.  State is <(-9.24, 3.69), 247.6, 0.15>.  Distance to center: 0.05, Distance from start 11.91, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 18.95.\n",
      "Iteration 98.  State is <(-9.29, 3.58), 253.6, 0.10>.  Distance to center: 0.05, Distance from start 12.03, Lidar 1.5, 3.8, 5.6, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.15.\n",
      "Iteration 99.  State is <(-9.33, 3.46), 247.6, 0.15>.  Distance to center: 0.05, Distance from start 12.16, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 19.35.\n",
      "Iteration 100.  State is <(-9.37, 3.34), 253.6, 0.10>.  Distance to center: 0.05, Distance from start 12.28, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.55.\n",
      "Iteration 101.  State is <(-9.41, 3.22), 247.6, 0.15>.  Distance to center: 0.05, Distance from start 12.41, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 19.75.\n",
      "Iteration 102.  State is <(-9.46, 3.11), 253.6, 0.10>.  Distance to center: 0.05, Distance from start 12.53, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 19.95.\n",
      "Iteration 103.  State is <(-9.50, 2.99), 247.6, 0.15>.  Distance to center: 0.04, Distance from start 12.66, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 20.15.\n",
      "Iteration 104.  State is <(-9.54, 2.87), 253.6, 0.10>.  Distance to center: 0.03, Distance from start 12.78, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 20.35.\n",
      "Iteration 105.  State is <(-9.57, 2.75), 259.6, 0.15>.  Distance to center: 0.04, Distance from start 12.91, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 20.55.\n",
      "Iteration 106.  State is <(-9.60, 2.63), 253.6, 0.10>.  Distance to center: 0.05, Distance from start 13.04, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 20.75.\n",
      "Iteration 107.  State is <(-9.63, 2.51), 259.6, 0.15>.  Distance to center: 0.05, Distance from start 13.16, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 20.95.\n",
      "Iteration 108.  State is <(-9.65, 2.38), 253.6, 0.10>.  Distance to center: 0.06, Distance from start 13.29, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 21.15.\n",
      "Iteration 109.  State is <(-9.68, 2.26), 259.6, 0.15>.  Distance to center: 0.06, Distance from start 13.41, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 21.35.\n",
      "Iteration 110.  State is <(-9.71, 2.14), 253.6, 0.10>.  Distance to center: 0.06, Distance from start 13.54, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 21.55.\n",
      "Iteration 111.  State is <(-9.74, 2.02), 259.6, 0.15>.  Distance to center: 0.06, Distance from start 13.66, Lidar 1.5, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 21.74.\n",
      "Iteration 112.  State is <(-9.77, 1.90), 253.6, 0.10>.  Distance to center: 0.05, Distance from start 13.79, Lidar 1.3, 2.7, 3.8, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 21.94.\n",
      "Iteration 113.  State is <(-9.79, 1.78), 259.6, 0.15>.  Distance to center: 0.05, Distance from start 13.91, Lidar 1.4, 3.2, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 22.14.\n",
      "Iteration 114.  State is <(-9.81, 1.65), 265.6, 0.10>.  Distance to center: 0.05, Distance from start 14.04, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 22.34.\n",
      "Iteration 115.  State is <(-9.83, 1.53), 259.6, 0.15>.  Distance to center: 0.05, Distance from start 14.16, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 22.54.\n",
      "Iteration 116.  State is <(-9.85, 1.41), 265.6, 0.10>.  Distance to center: 0.06, Distance from start 14.29, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 22.74.\n",
      "Iteration 117.  State is <(-9.86, 1.28), 259.6, 0.15>.  Distance to center: 0.05, Distance from start 14.42, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 22.94.\n",
      "Iteration 118.  State is <(-9.88, 1.16), 265.6, 0.10>.  Distance to center: 0.05, Distance from start 14.54, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 23.14.\n",
      "Iteration 119.  State is <(-9.90, 1.03), 259.6, 0.15>.  Distance to center: 0.05, Distance from start 14.67, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 23.34.\n",
      "Iteration 120.  State is <(-9.92, 0.91), 265.6, 0.10>.  Distance to center: 0.04, Distance from start 14.79, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 23.54.\n",
      "Iteration 121.  State is <(-9.93, 0.79), 259.6, 0.15>.  Distance to center: 0.04, Distance from start 14.92, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 23.74.\n",
      "Iteration 122.  State is <(-9.95, 0.66), 265.6, 0.10>.  Distance to center: 0.03, Distance from start 15.04, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 23.94.\n",
      "Iteration 123.  State is <(-9.95, 0.54), 271.6, 0.15>.  Distance to center: 0.03, Distance from start 15.17, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.14.\n",
      "Iteration 124.  State is <(-9.95, 0.41), 265.6, 0.10>.  Distance to center: 0.04, Distance from start 15.29, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 24.34.\n",
      "Iteration 125.  State is <(-9.96, 0.29), 271.6, 0.15>.  Distance to center: 0.04, Distance from start 15.42, Lidar 1.5, 3.6, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.54.\n",
      "Iteration 126.  State is <(-9.96, 0.16), 265.6, 0.10>.  Distance to center: 0.04, Distance from start 15.54, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 24.74.\n",
      "Iteration 127.  State is <(-9.96, 0.04), 271.6, 0.15>.  Distance to center: 0.04, Distance from start 15.67, Lidar 1.4, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 24.94.\n",
      "Iteration 128.  State is <(-9.96, -0.09), 265.6, 0.10>.  Distance to center: 0.04, Distance from start 15.79, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 25.14.\n",
      "Iteration 129.  State is <(-9.96, -0.21), 271.6, 0.15>.  Distance to center: 0.04, Distance from start 15.92, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 25.34.\n",
      "Iteration 130.  State is <(-9.95, -0.33), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 16.04, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 25.53.\n",
      "Iteration 131.  State is <(-9.95, -0.46), 271.6, 0.15>.  Distance to center: 0.04, Distance from start 16.17, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 25.73.\n",
      "Iteration 132.  State is <(-9.94, -0.58), 277.6, 0.10>.  Distance to center: 0.05, Distance from start 16.29, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 25.93.\n",
      "Iteration 133.  State is <(-9.93, -0.71), 271.6, 0.15>.  Distance to center: 0.05, Distance from start 16.42, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 26.13.\n",
      "Iteration 134.  State is <(-9.92, -0.83), 277.6, 0.10>.  Distance to center: 0.05, Distance from start 16.55, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 26.33.\n",
      "Iteration 135.  State is <(-9.91, -0.96), 271.6, 0.15>.  Distance to center: 0.04, Distance from start 16.67, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 26.53.\n",
      "Iteration 136.  State is <(-9.90, -1.08), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 16.80, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 26.73.\n",
      "Iteration 137.  State is <(-9.89, -1.21), 271.6, 0.15>.  Distance to center: 0.03, Distance from start 16.92, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 26.93.\n",
      "Iteration 138.  State is <(-9.89, -1.33), 277.6, 0.10>.  Distance to center: 0.03, Distance from start 17.05, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 27.13.\n",
      "Iteration 139.  State is <(-9.86, -1.45), 283.6, 0.15>.  Distance to center: 0.03, Distance from start 17.17, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 27.33.\n",
      "Iteration 140.  State is <(-9.84, -1.58), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 17.30, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 27.53.\n",
      "Iteration 141.  State is <(-9.81, -1.70), 283.6, 0.15>.  Distance to center: 0.04, Distance from start 17.42, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 27.73.\n",
      "Iteration 142.  State is <(-9.79, -1.82), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 17.55, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 27.93.\n",
      "Iteration 143.  State is <(-9.76, -1.94), 283.6, 0.15>.  Distance to center: 0.04, Distance from start 17.67, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 28.13.\n",
      "Iteration 144.  State is <(-9.74, -2.07), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 17.80, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 28.33.\n",
      "Iteration 145.  State is <(-9.72, -2.19), 283.6, 0.15>.  Distance to center: 0.04, Distance from start 17.92, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 28.53.\n",
      "Iteration 146.  State is <(-9.69, -2.31), 277.6, 0.10>.  Distance to center: 0.04, Distance from start 18.05, Lidar 1.3, 2.7, 3.8, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 28.72.\n",
      "Iteration 147.  State is <(-9.67, -2.43), 283.6, 0.15>.  Distance to center: 0.03, Distance from start 18.17, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 28.92.\n",
      "Iteration 148.  State is <(-9.63, -2.55), 289.6, 0.10>.  Distance to center: 0.03, Distance from start 18.30, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.12.\n",
      "Iteration 149.  State is <(-9.60, -2.67), 283.6, 0.15>.  Distance to center: 0.04, Distance from start 18.42, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 29.32.\n",
      "Iteration 150.  State is <(-9.56, -2.79), 289.6, 0.10>.  Distance to center: 0.04, Distance from start 18.55, Lidar 1.5, 3.6, 5.3, 7.5, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.52.\n",
      "Iteration 151.  State is <(-9.53, -2.91), 283.6, 0.15>.  Distance to center: 0.03, Distance from start 18.67, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 29.72.\n",
      "Iteration 152.  State is <(-9.50, -3.03), 289.6, 0.10>.  Distance to center: 0.03, Distance from start 18.80, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 29.92.\n",
      "Iteration 153.  State is <(-9.46, -3.15), 283.6, 0.15>.  Distance to center: 0.03, Distance from start 18.92, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 30.12.\n",
      "Iteration 154.  State is <(-9.43, -3.27), 289.6, 0.10>.  Distance to center: 0.02, Distance from start 19.05, Lidar 1.4, 3.3, 4.7, 6.8, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 30.32.\n",
      "Iteration 155.  State is <(-9.38, -3.39), 295.6, 0.15>.  Distance to center: 0.03, Distance from start 19.17, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 30.52.\n",
      "Iteration 156.  State is <(-9.33, -3.50), 289.6, 0.10>.  Distance to center: 0.03, Distance from start 19.30, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 30.72.\n",
      "Iteration 157.  State is <(-9.28, -3.62), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 19.42, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 30.92.\n",
      "Iteration 158.  State is <(-9.23, -3.73), 289.6, 0.10>.  Distance to center: 0.04, Distance from start 19.55, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 31.12.\n",
      "Iteration 159.  State is <(-9.18, -3.85), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 19.68, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 31.31.\n",
      "Iteration 160.  State is <(-9.13, -3.96), 289.6, 0.10>.  Distance to center: 0.04, Distance from start 19.80, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 31.51.\n",
      "Iteration 161.  State is <(-9.08, -4.08), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 19.93, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 31.71.\n",
      "Iteration 162.  State is <(-9.03, -4.19), 289.6, 0.10>.  Distance to center: 0.04, Distance from start 20.05, Lidar 1.3, 2.7, 3.8, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 31.91.\n",
      "Iteration 163.  State is <(-8.99, -4.31), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 20.18, Lidar 1.4, 3.2, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 32.11.\n",
      "Iteration 164.  State is <(-8.93, -4.42), 301.6, 0.10>.  Distance to center: 0.04, Distance from start 20.30, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 32.31.\n",
      "Iteration 165.  State is <(-8.87, -4.53), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 20.43, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 32.51.\n",
      "Iteration 166.  State is <(-8.81, -4.64), 301.6, 0.10>.  Distance to center: 0.04, Distance from start 20.55, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 32.71.\n",
      "Iteration 167.  State is <(-8.75, -4.75), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 20.68, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 32.91.\n",
      "Iteration 168.  State is <(-8.69, -4.86), 301.6, 0.10>.  Distance to center: 0.04, Distance from start 20.80, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 33.11.\n",
      "Iteration 169.  State is <(-8.63, -4.97), 295.6, 0.15>.  Distance to center: 0.04, Distance from start 20.93, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 33.31.\n",
      "Iteration 170.  State is <(-8.58, -5.08), 301.6, 0.10>.  Distance to center: 0.03, Distance from start 21.05, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 33.51.\n",
      "Iteration 171.  State is <(-8.50, -5.18), 307.6, 0.15>.  Distance to center: 0.04, Distance from start 21.18, Lidar 1.6, 4.1, 5.9, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 33.71.\n",
      "Iteration 172.  State is <(-8.43, -5.28), 301.6, 0.10>.  Distance to center: 0.05, Distance from start 21.30, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 33.91.\n",
      "Iteration 173.  State is <(-8.36, -5.38), 307.6, 0.15>.  Distance to center: 0.06, Distance from start 21.43, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.11.\n",
      "Iteration 174.  State is <(-8.29, -5.49), 301.6, 0.10>.  Distance to center: 0.06, Distance from start 21.56, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 34.31.\n",
      "Iteration 175.  State is <(-8.22, -5.59), 307.6, 0.15>.  Distance to center: 0.06, Distance from start 21.68, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.51.\n",
      "Iteration 176.  State is <(-8.14, -5.69), 301.6, 0.10>.  Distance to center: 0.06, Distance from start 21.81, Lidar 1.4, 3.0, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 34.71.\n",
      "Iteration 177.  State is <(-8.07, -5.79), 307.6, 0.15>.  Distance to center: 0.06, Distance from start 21.93, Lidar 1.5, 3.5, 5.1, 7.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 34.91.\n",
      "Iteration 178.  State is <(-8.00, -5.89), 301.6, 0.10>.  Distance to center: 0.06, Distance from start 22.06, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 35.11.\n",
      "Iteration 179.  State is <(-7.93, -6.00), 307.6, 0.15>.  Distance to center: 0.06, Distance from start 22.18, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 35.31.\n",
      "Iteration 180.  State is <(-7.86, -6.10), 301.6, 0.10>.  Distance to center: 0.05, Distance from start 22.31, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 35.51.\n",
      "Iteration 181.  State is <(-7.79, -6.20), 307.6, 0.15>.  Distance to center: 0.05, Distance from start 22.43, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 35.70.\n",
      "Iteration 182.  State is <(-7.70, -6.30), 313.6, 0.10>.  Distance to center: 0.05, Distance from start 22.56, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 35.90.\n",
      "Iteration 183.  State is <(-7.62, -6.39), 307.6, 0.15>.  Distance to center: 0.05, Distance from start 22.68, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 36.10.\n",
      "Iteration 184.  State is <(-7.54, -6.49), 313.6, 0.10>.  Distance to center: 0.05, Distance from start 22.81, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 36.30.\n",
      "Iteration 185.  State is <(-7.46, -6.58), 307.6, 0.15>.  Distance to center: 0.05, Distance from start 22.94, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 36.50.\n",
      "Iteration 186.  State is <(-7.38, -6.68), 313.6, 0.10>.  Distance to center: 0.04, Distance from start 23.06, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 36.70.\n",
      "Iteration 187.  State is <(-7.30, -6.77), 307.6, 0.15>.  Distance to center: 0.04, Distance from start 23.19, Lidar 1.3, 2.7, 3.8, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 36.90.\n",
      "Iteration 188.  State is <(-7.22, -6.87), 313.6, 0.10>.  Distance to center: 0.03, Distance from start 23.31, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 37.10.\n",
      "Iteration 189.  State is <(-7.13, -6.96), 319.6, 0.15>.  Distance to center: 0.04, Distance from start 23.44, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 37.30.\n",
      "Iteration 190.  State is <(-7.04, -7.04), 313.6, 0.10>.  Distance to center: 0.04, Distance from start 23.56, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 37.50.\n",
      "Iteration 191.  State is <(-6.95, -7.13), 319.6, 0.15>.  Distance to center: 0.05, Distance from start 23.69, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 37.70.\n",
      "Iteration 192.  State is <(-6.86, -7.21), 313.6, 0.10>.  Distance to center: 0.05, Distance from start 23.81, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 37.90.\n",
      "Iteration 193.  State is <(-6.77, -7.29), 319.6, 0.15>.  Distance to center: 0.05, Distance from start 23.94, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 38.10.\n",
      "Iteration 194.  State is <(-6.67, -7.38), 313.6, 0.10>.  Distance to center: 0.05, Distance from start 24.06, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 38.30.\n",
      "Iteration 195.  State is <(-6.58, -7.46), 319.6, 0.15>.  Distance to center: 0.05, Distance from start 24.19, Lidar 1.4, 3.4, 4.9, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 38.50.\n",
      "Iteration 196.  State is <(-6.49, -7.55), 313.6, 0.10>.  Distance to center: 0.04, Distance from start 24.31, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 38.70.\n",
      "Iteration 197.  State is <(-6.40, -7.63), 319.6, 0.15>.  Distance to center: 0.04, Distance from start 24.44, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 38.90.\n",
      "Iteration 198.  State is <(-6.30, -7.71), 325.6, 0.10>.  Distance to center: 0.04, Distance from start 24.56, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.10.\n",
      "Iteration 199.  State is <(-6.20, -7.79), 319.6, 0.15>.  Distance to center: 0.04, Distance from start 24.69, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 39.30.\n",
      "Iteration 200.  State is <(-6.11, -7.87), 325.6, 0.10>.  Distance to center: 0.04, Distance from start 24.82, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.49.\n",
      "Iteration 201.  State is <(-6.01, -7.94), 319.6, 0.15>.  Distance to center: 0.04, Distance from start 24.94, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 39.69.\n",
      "Iteration 202.  State is <(-5.91, -8.02), 325.6, 0.10>.  Distance to center: 0.04, Distance from start 25.07, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 39.89.\n",
      "Iteration 203.  State is <(-5.81, -8.10), 319.6, 0.15>.  Distance to center: 0.03, Distance from start 25.19, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 40.09.\n",
      "Iteration 204.  State is <(-5.71, -8.17), 325.6, 0.10>.  Distance to center: 0.03, Distance from start 25.32, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 40.29.\n",
      "Iteration 205.  State is <(-5.60, -8.24), 331.6, 0.15>.  Distance to center: 0.04, Distance from start 25.44, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 40.49.\n",
      "Iteration 206.  State is <(-5.50, -8.30), 325.6, 0.10>.  Distance to center: 0.04, Distance from start 25.57, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 40.69.\n",
      "Iteration 207.  State is <(-5.39, -8.36), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 25.69, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 40.89.\n",
      "Iteration 208.  State is <(-5.28, -8.43), 325.6, 0.10>.  Distance to center: 0.05, Distance from start 25.82, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 41.09.\n",
      "Iteration 209.  State is <(-5.18, -8.49), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 25.94, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 41.29.\n",
      "Iteration 210.  State is <(-5.07, -8.56), 325.6, 0.10>.  Distance to center: 0.05, Distance from start 26.07, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 41.49.\n",
      "Iteration 211.  State is <(-4.96, -8.62), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 26.19, Lidar 1.5, 3.4, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 41.69.\n",
      "Iteration 212.  State is <(-4.85, -8.68), 325.6, 0.10>.  Distance to center: 0.05, Distance from start 26.32, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 41.89.\n",
      "Iteration 213.  State is <(-4.75, -8.75), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 26.44, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 42.09.\n",
      "Iteration 214.  State is <(-4.64, -8.80), 337.6, 0.10>.  Distance to center: 0.05, Distance from start 26.57, Lidar 1.5, 4.0, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 42.29.\n",
      "Iteration 215.  State is <(-4.52, -8.86), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 26.70, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 42.49.\n",
      "Iteration 216.  State is <(-4.41, -8.91), 337.6, 0.10>.  Distance to center: 0.06, Distance from start 26.82, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 42.69.\n",
      "Iteration 217.  State is <(-4.30, -8.97), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 26.95, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 42.89.\n",
      "Iteration 218.  State is <(-4.19, -9.02), 337.6, 0.10>.  Distance to center: 0.05, Distance from start 27.07, Lidar 1.5, 3.6, 5.1, 7.3, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 43.09.\n",
      "Iteration 219.  State is <(-4.07, -9.08), 331.6, 0.15>.  Distance to center: 0.05, Distance from start 27.20, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 43.29.\n",
      "Iteration 220.  State is <(-3.96, -9.13), 337.6, 0.10>.  Distance to center: 0.04, Distance from start 27.32, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 43.49.\n",
      "Iteration 221.  State is <(-3.85, -9.19), 331.6, 0.15>.  Distance to center: 0.04, Distance from start 27.45, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 43.68.\n",
      "Iteration 222.  State is <(-3.74, -9.24), 337.6, 0.10>.  Distance to center: 0.03, Distance from start 27.57, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 43.88.\n",
      "Iteration 223.  State is <(-3.62, -9.28), 343.6, 0.15>.  Distance to center: 0.04, Distance from start 27.70, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.08.\n",
      "Iteration 224.  State is <(-3.50, -9.32), 337.6, 0.10>.  Distance to center: 0.04, Distance from start 27.82, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 44.28.\n",
      "Iteration 225.  State is <(-3.38, -9.36), 343.6, 0.15>.  Distance to center: 0.04, Distance from start 27.95, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.48.\n",
      "Iteration 226.  State is <(-3.27, -9.40), 337.6, 0.10>.  Distance to center: 0.05, Distance from start 28.07, Lidar 1.4, 2.9, 4.1, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 44.68.\n",
      "Iteration 227.  State is <(-3.15, -9.44), 343.6, 0.15>.  Distance to center: 0.05, Distance from start 28.20, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 44.88.\n",
      "Iteration 228.  State is <(-3.03, -9.48), 337.6, 0.10>.  Distance to center: 0.04, Distance from start 28.32, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 45.08.\n",
      "Iteration 229.  State is <(-2.91, -9.52), 343.6, 0.15>.  Distance to center: 0.04, Distance from start 28.45, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 45.28.\n",
      "Iteration 230.  State is <(-2.79, -9.55), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 28.58, Lidar 1.6, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 45.48.\n",
      "Iteration 231.  State is <(-2.67, -9.58), 343.6, 0.15>.  Distance to center: 0.05, Distance from start 28.70, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 45.68.\n",
      "Iteration 232.  State is <(-2.55, -9.62), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 28.83, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 45.88.\n",
      "Iteration 233.  State is <(-2.43, -9.65), 343.6, 0.15>.  Distance to center: 0.05, Distance from start 28.95, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 46.08.\n",
      "Iteration 234.  State is <(-2.31, -9.68), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 29.08, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 46.28.\n",
      "Iteration 235.  State is <(-2.18, -9.71), 343.6, 0.15>.  Distance to center: 0.05, Distance from start 29.20, Lidar 1.4, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 46.48.\n",
      "Iteration 236.  State is <(-2.06, -9.74), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 29.33, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 46.68.\n",
      "Iteration 237.  State is <(-1.94, -9.77), 343.6, 0.15>.  Distance to center: 0.04, Distance from start 29.45, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 46.88.\n",
      "Iteration 238.  State is <(-1.82, -9.80), 349.6, 0.10>.  Distance to center: 0.04, Distance from start 29.58, Lidar 1.4, 3.2, 4.7, 6.7, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 47.08.\n",
      "Iteration 239.  State is <(-1.70, -9.81), 355.6, 0.15>.  Distance to center: 0.04, Distance from start 29.70, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 47.27.\n",
      "Iteration 240.  State is <(-1.57, -9.83), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 29.83, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 47.47.\n",
      "Iteration 241.  State is <(-1.45, -9.84), 355.6, 0.15>.  Distance to center: 0.05, Distance from start 29.95, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 47.67.\n",
      "Iteration 242.  State is <(-1.33, -9.86), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 30.08, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 47.87.\n",
      "Iteration 243.  State is <(-1.20, -9.87), 355.6, 0.15>.  Distance to center: 0.06, Distance from start 30.21, Lidar 1.5, 3.6, 5.2, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 48.07.\n",
      "Iteration 244.  State is <(-1.08, -9.89), 349.6, 0.10>.  Distance to center: 0.06, Distance from start 30.33, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 48.27.\n",
      "Iteration 245.  State is <(-0.95, -9.90), 355.6, 0.15>.  Distance to center: 0.05, Distance from start 30.46, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 48.47.\n",
      "Iteration 246.  State is <(-0.83, -9.92), 349.6, 0.10>.  Distance to center: 0.05, Distance from start 30.58, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 48.67.\n",
      "Iteration 247.  State is <(-0.71, -9.93), 355.6, 0.15>.  Distance to center: 0.04, Distance from start 30.71, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 48.87.\n",
      "Iteration 248.  State is <(-0.58, -9.94), 1.6, 0.10>.  Distance to center: 0.05, Distance from start 30.83, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.07.\n",
      "Iteration 249.  State is <(-0.46, -9.94), -4.4, 0.15>.  Distance to center: 0.05, Distance from start 30.96, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 49.27.\n",
      "Iteration 250.  State is <(-0.33, -9.94), 1.6, 0.10>.  Distance to center: 0.05, Distance from start 31.08, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.47.\n",
      "Iteration 251.  State is <(-0.21, -9.95), -4.4, 0.15>.  Distance to center: 0.05, Distance from start 31.21, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 49.67.\n",
      "Iteration 252.  State is <(-0.08, -9.95), 1.6, 0.10>.  Distance to center: 0.05, Distance from start 31.33, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 49.87.\n",
      "Iteration 253.  State is <(0.04, -9.96), -4.4, 0.15>.  Distance to center: 0.04, Distance from start 31.46, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 50.07.\n",
      "Iteration 254.  State is <(0.17, -9.96), 1.6, 0.10>.  Distance to center: 0.04, Distance from start 31.58, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 50.27.\n",
      "Iteration 255.  State is <(0.29, -9.95), 7.6, 0.15>.  Distance to center: 0.05, Distance from start 31.71, Lidar 1.6, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 50.47.\n",
      "Iteration 256.  State is <(0.42, -9.94), 1.6, 0.10>.  Distance to center: 0.05, Distance from start 31.83, Lidar 1.4, 3.2, 4.6, 6.5, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 50.67.\n",
      "Iteration 257.  State is <(0.54, -9.93), 7.6, 0.15>.  Distance to center: 0.06, Distance from start 31.96, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 50.87.\n",
      "Iteration 258.  State is <(0.67, -9.92), 1.6, 0.10>.  Distance to center: 0.06, Distance from start 32.09, Lidar 1.4, 3.1, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 51.07.\n",
      "Iteration 259.  State is <(0.79, -9.91), 7.6, 0.15>.  Distance to center: 0.06, Distance from start 32.21, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 51.27.\n",
      "Iteration 260.  State is <(0.91, -9.89), 1.6, 0.10>.  Distance to center: 0.06, Distance from start 32.34, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 51.47.\n",
      "Iteration 261.  State is <(1.04, -9.88), 7.6, 0.15>.  Distance to center: 0.06, Distance from start 32.46, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 51.67.\n",
      "Iteration 262.  State is <(1.16, -9.87), 1.6, 0.10>.  Distance to center: 0.06, Distance from start 32.59, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 51.87.\n",
      "Iteration 263.  State is <(1.29, -9.86), 7.6, 0.15>.  Distance to center: 0.06, Distance from start 32.71, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 52.07.\n",
      "Iteration 264.  State is <(1.41, -9.85), 1.6, 0.10>.  Distance to center: 0.05, Distance from start 32.84, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 52.27.\n",
      "Iteration 265.  State is <(1.54, -9.84), 7.6, 0.15>.  Distance to center: 0.04, Distance from start 32.96, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 52.46.\n",
      "Iteration 266.  State is <(1.66, -9.82), 13.6, 0.10>.  Distance to center: 0.04, Distance from start 33.09, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 52.66.\n",
      "Iteration 267.  State is <(1.78, -9.80), 7.6, 0.15>.  Distance to center: 0.04, Distance from start 33.22, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 52.86.\n",
      "Iteration 268.  State is <(1.90, -9.77), 13.6, 0.10>.  Distance to center: 0.04, Distance from start 33.34, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 53.06.\n",
      "Iteration 269.  State is <(2.03, -9.75), 7.6, 0.15>.  Distance to center: 0.04, Distance from start 33.47, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 53.26.\n",
      "Iteration 270.  State is <(2.15, -9.73), 13.6, 0.10>.  Distance to center: 0.03, Distance from start 33.59, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 53.46.\n",
      "Iteration 271.  State is <(2.27, -9.71), 7.6, 0.15>.  Distance to center: 0.03, Distance from start 33.72, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 53.66.\n",
      "Iteration 272.  State is <(2.40, -9.69), 13.6, 0.10>.  Distance to center: 0.02, Distance from start 33.84, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 53.86.\n",
      "Iteration 273.  State is <(2.52, -9.65), 19.6, 0.15>.  Distance to center: 0.03, Distance from start 33.97, Lidar 1.5, 3.8, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.06.\n",
      "Iteration 274.  State is <(2.63, -9.61), 13.6, 0.10>.  Distance to center: 0.03, Distance from start 34.09, Lidar 1.4, 3.0, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 54.26.\n",
      "Iteration 275.  State is <(2.75, -9.58), 19.6, 0.15>.  Distance to center: 0.04, Distance from start 34.22, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.46.\n",
      "Iteration 276.  State is <(2.87, -9.54), 13.6, 0.10>.  Distance to center: 0.04, Distance from start 34.34, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 54.66.\n",
      "Iteration 277.  State is <(2.99, -9.50), 19.6, 0.15>.  Distance to center: 0.04, Distance from start 34.47, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 54.86.\n",
      "Iteration 278.  State is <(3.11, -9.47), 13.6, 0.10>.  Distance to center: 0.04, Distance from start 34.59, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 55.06.\n",
      "Iteration 279.  State is <(3.23, -9.43), 19.6, 0.15>.  Distance to center: 0.03, Distance from start 34.72, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 55.25.\n",
      "Iteration 280.  State is <(3.35, -9.38), 25.6, 0.10>.  Distance to center: 0.04, Distance from start 34.84, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 55.45.\n",
      "Iteration 281.  State is <(3.46, -9.34), 19.6, 0.15>.  Distance to center: 0.04, Distance from start 34.97, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 55.65.\n",
      "Iteration 282.  State is <(3.58, -9.29), 25.6, 0.10>.  Distance to center: 0.05, Distance from start 35.09, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 55.85.\n",
      "Iteration 283.  State is <(3.69, -9.24), 19.6, 0.15>.  Distance to center: 0.05, Distance from start 35.22, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 56.05.\n",
      "Iteration 284.  State is <(3.81, -9.20), 25.6, 0.10>.  Distance to center: 0.05, Distance from start 35.34, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 56.25.\n",
      "Iteration 285.  State is <(3.93, -9.15), 19.6, 0.15>.  Distance to center: 0.04, Distance from start 35.47, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 56.45.\n",
      "Iteration 286.  State is <(4.04, -9.10), 25.6, 0.10>.  Distance to center: 0.04, Distance from start 35.59, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 56.65.\n",
      "Iteration 287.  State is <(4.16, -9.06), 19.6, 0.15>.  Distance to center: 0.04, Distance from start 35.72, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 56.85.\n",
      "Iteration 288.  State is <(4.27, -9.01), 25.6, 0.10>.  Distance to center: 0.03, Distance from start 35.84, Lidar 1.4, 3.2, 4.7, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 57.05.\n",
      "Iteration 289.  State is <(4.38, -8.95), 31.6, 0.15>.  Distance to center: 0.04, Distance from start 35.97, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 57.25.\n",
      "Iteration 290.  State is <(4.49, -8.89), 25.6, 0.10>.  Distance to center: 0.04, Distance from start 36.10, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 57.45.\n",
      "Iteration 291.  State is <(4.60, -8.83), 31.6, 0.15>.  Distance to center: 0.05, Distance from start 36.22, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 57.65.\n",
      "Iteration 292.  State is <(4.71, -8.77), 25.6, 0.10>.  Distance to center: 0.05, Distance from start 36.35, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 57.85.\n",
      "Iteration 293.  State is <(4.82, -8.71), 31.6, 0.15>.  Distance to center: 0.05, Distance from start 36.47, Lidar 1.5, 3.6, 5.2, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 58.05.\n",
      "Iteration 294.  State is <(4.93, -8.64), 25.6, 0.10>.  Distance to center: 0.05, Distance from start 36.60, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 58.25.\n",
      "Iteration 295.  State is <(5.04, -8.58), 31.6, 0.15>.  Distance to center: 0.05, Distance from start 36.72, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 58.45.\n",
      "Iteration 296.  State is <(5.15, -8.52), 25.6, 0.10>.  Distance to center: 0.04, Distance from start 36.85, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 58.64.\n",
      "Iteration 297.  State is <(5.25, -8.46), 31.6, 0.15>.  Distance to center: 0.04, Distance from start 36.97, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 58.84.\n",
      "Iteration 298.  State is <(5.36, -8.39), 37.6, 0.10>.  Distance to center: 0.04, Distance from start 37.10, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.04.\n",
      "Iteration 299.  State is <(5.46, -8.32), 31.6, 0.15>.  Distance to center: 0.05, Distance from start 37.22, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 59.24.\n",
      "Iteration 300.  State is <(5.57, -8.25), 37.6, 0.10>.  Distance to center: 0.05, Distance from start 37.35, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.44.\n",
      "Iteration 301.  State is <(5.67, -8.18), 31.6, 0.15>.  Distance to center: 0.05, Distance from start 37.47, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 59.64.\n",
      "Iteration 302.  State is <(5.77, -8.11), 37.6, 0.10>.  Distance to center: 0.04, Distance from start 37.60, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 59.84.\n",
      "Iteration 303.  State is <(5.88, -8.04), 31.6, 0.15>.  Distance to center: 0.04, Distance from start 37.72, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 60.04.\n",
      "Iteration 304.  State is <(5.98, -7.97), 37.6, 0.10>.  Distance to center: 0.03, Distance from start 37.85, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 60.24.\n",
      "Iteration 305.  State is <(6.07, -7.89), 43.6, 0.15>.  Distance to center: 0.04, Distance from start 37.98, Lidar 1.6, 4.0, 5.8, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 60.44.\n",
      "Iteration 306.  State is <(6.17, -7.81), 37.6, 0.10>.  Distance to center: 0.05, Distance from start 38.10, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 60.64.\n",
      "Iteration 307.  State is <(6.26, -7.73), 43.6, 0.15>.  Distance to center: 0.05, Distance from start 38.23, Lidar 1.5, 3.8, 5.6, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 60.84.\n",
      "Iteration 308.  State is <(6.36, -7.65), 37.6, 0.10>.  Distance to center: 0.06, Distance from start 38.35, Lidar 1.4, 3.1, 4.3, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 61.04.\n",
      "Iteration 309.  State is <(6.45, -7.56), 43.6, 0.15>.  Distance to center: 0.06, Distance from start 38.48, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 61.24.\n",
      "Iteration 310.  State is <(6.54, -7.48), 37.6, 0.10>.  Distance to center: 0.06, Distance from start 38.60, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 61.44.\n",
      "Iteration 311.  State is <(6.64, -7.40), 43.6, 0.15>.  Distance to center: 0.06, Distance from start 38.73, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 61.64.\n",
      "Iteration 312.  State is <(6.73, -7.32), 37.6, 0.10>.  Distance to center: 0.06, Distance from start 38.85, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 61.84.\n",
      "Iteration 313.  State is <(6.83, -7.23), 43.6, 0.15>.  Distance to center: 0.05, Distance from start 38.98, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 62.04.\n",
      "Iteration 314.  State is <(6.92, -7.15), 37.6, 0.10>.  Distance to center: 0.05, Distance from start 39.10, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 62.24.\n",
      "Iteration 315.  State is <(7.01, -7.07), 43.6, 0.15>.  Distance to center: 0.04, Distance from start 39.23, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 62.44.\n",
      "Iteration 316.  State is <(7.10, -6.98), 49.6, 0.10>.  Distance to center: 0.04, Distance from start 39.35, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 62.64.\n",
      "Iteration 317.  State is <(7.19, -6.89), 43.6, 0.15>.  Distance to center: 0.04, Distance from start 39.48, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 62.83.\n",
      "Iteration 318.  State is <(7.27, -6.80), 49.6, 0.10>.  Distance to center: 0.04, Distance from start 39.61, Lidar 1.5, 3.6, 5.2, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 63.03.\n",
      "Iteration 319.  State is <(7.36, -6.71), 43.6, 0.15>.  Distance to center: 0.04, Distance from start 39.73, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 63.23.\n",
      "Iteration 320.  State is <(7.45, -6.62), 49.6, 0.10>.  Distance to center: 0.04, Distance from start 39.86, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 63.43.\n",
      "Iteration 321.  State is <(7.53, -6.53), 43.6, 0.15>.  Distance to center: 0.03, Distance from start 39.98, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 63.63.\n",
      "Iteration 322.  State is <(7.62, -6.44), 49.6, 0.10>.  Distance to center: 0.02, Distance from start 40.11, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 63.83.\n",
      "Iteration 323.  State is <(7.70, -6.34), 55.6, 0.15>.  Distance to center: 0.03, Distance from start 40.23, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.03.\n",
      "Iteration 324.  State is <(7.77, -6.24), 49.6, 0.10>.  Distance to center: 0.03, Distance from start 40.36, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 64.23.\n",
      "Iteration 325.  State is <(7.85, -6.14), 55.6, 0.15>.  Distance to center: 0.04, Distance from start 40.48, Lidar 1.5, 3.7, 5.3, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.43.\n",
      "Iteration 326.  State is <(7.92, -6.04), 49.6, 0.10>.  Distance to center: 0.04, Distance from start 40.61, Lidar 1.3, 2.9, 4.2, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 64.63.\n",
      "Iteration 327.  State is <(7.99, -5.94), 55.6, 0.15>.  Distance to center: 0.04, Distance from start 40.73, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 64.83.\n",
      "Iteration 328.  State is <(8.07, -5.84), 49.6, 0.10>.  Distance to center: 0.04, Distance from start 40.86, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 65.03.\n",
      "Iteration 329.  State is <(8.14, -5.74), 55.6, 0.15>.  Distance to center: 0.03, Distance from start 40.98, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 65.23.\n",
      "Iteration 330.  State is <(8.21, -5.64), 61.6, 0.10>.  Distance to center: 0.04, Distance from start 41.11, Lidar 1.5, 4.0, 5.8, 8.2, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 65.43.\n",
      "Iteration 331.  State is <(8.28, -5.53), 55.6, 0.15>.  Distance to center: 0.05, Distance from start 41.23, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 65.62.\n",
      "Iteration 332.  State is <(8.34, -5.43), 61.6, 0.10>.  Distance to center: 0.05, Distance from start 41.36, Lidar 1.5, 3.8, 5.6, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 65.82.\n",
      "Iteration 333.  State is <(8.41, -5.32), 55.6, 0.15>.  Distance to center: 0.05, Distance from start 41.48, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 66.02.\n",
      "Iteration 334.  State is <(8.48, -5.21), 61.6, 0.10>.  Distance to center: 0.05, Distance from start 41.61, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 66.22.\n",
      "Iteration 335.  State is <(8.54, -5.11), 55.6, 0.15>.  Distance to center: 0.05, Distance from start 41.73, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 66.42.\n",
      "Iteration 336.  State is <(8.61, -5.00), 61.6, 0.10>.  Distance to center: 0.04, Distance from start 41.86, Lidar 1.4, 3.5, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 66.62.\n",
      "Iteration 337.  State is <(8.67, -4.90), 55.6, 0.15>.  Distance to center: 0.04, Distance from start 41.99, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 66.82.\n",
      "Iteration 338.  State is <(8.74, -4.79), 61.6, 0.10>.  Distance to center: 0.03, Distance from start 42.11, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 67.02.\n",
      "Iteration 339.  State is <(8.79, -4.68), 67.6, 0.15>.  Distance to center: 0.04, Distance from start 42.24, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 67.22.\n",
      "Iteration 340.  State is <(8.85, -4.56), 61.6, 0.10>.  Distance to center: 0.05, Distance from start 42.36, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 67.42.\n",
      "Iteration 341.  State is <(8.90, -4.45), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 42.49, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 67.62.\n",
      "Iteration 342.  State is <(8.95, -4.34), 61.6, 0.10>.  Distance to center: 0.05, Distance from start 42.61, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 67.82.\n",
      "Iteration 343.  State is <(9.00, -4.22), 67.6, 0.15>.  Distance to center: 0.06, Distance from start 42.74, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 68.02.\n",
      "Iteration 344.  State is <(9.06, -4.11), 61.6, 0.10>.  Distance to center: 0.06, Distance from start 42.86, Lidar 1.4, 2.9, 4.1, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 68.22.\n",
      "Iteration 345.  State is <(9.11, -4.00), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 42.99, Lidar 1.5, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 68.42.\n",
      "Iteration 346.  State is <(9.16, -3.88), 61.6, 0.10>.  Distance to center: 0.05, Distance from start 43.11, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 68.62.\n",
      "Iteration 347.  State is <(9.21, -3.77), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 43.24, Lidar 1.4, 3.2, 4.6, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 68.82.\n",
      "Iteration 348.  State is <(9.26, -3.65), 73.6, 0.10>.  Distance to center: 0.05, Distance from start 43.36, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.02.\n",
      "Iteration 349.  State is <(9.30, -3.54), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 43.49, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 69.22.\n",
      "Iteration 350.  State is <(9.34, -3.42), 73.6, 0.10>.  Distance to center: 0.05, Distance from start 43.62, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.42.\n",
      "Iteration 351.  State is <(9.38, -3.30), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 43.74, Lidar 1.4, 3.0, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 69.62.\n",
      "Iteration 352.  State is <(9.43, -3.18), 73.6, 0.10>.  Distance to center: 0.05, Distance from start 43.87, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 69.82.\n",
      "Iteration 353.  State is <(9.47, -3.07), 67.6, 0.15>.  Distance to center: 0.05, Distance from start 43.99, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 70.01.\n",
      "Iteration 354.  State is <(9.51, -2.95), 73.6, 0.10>.  Distance to center: 0.04, Distance from start 44.12, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 70.21.\n",
      "Iteration 355.  State is <(9.55, -2.83), 67.6, 0.15>.  Distance to center: 0.03, Distance from start 44.24, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 70.41.\n",
      "Iteration 356.  State is <(9.60, -2.72), 73.6, 0.10>.  Distance to center: 0.03, Distance from start 44.37, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 70.61.\n",
      "Iteration 357.  State is <(9.63, -2.59), 79.6, 0.15>.  Distance to center: 0.03, Distance from start 44.49, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 70.81.\n",
      "Iteration 358.  State is <(9.65, -2.47), 73.6, 0.10>.  Distance to center: 0.04, Distance from start 44.62, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 71.01.\n",
      "Iteration 359.  State is <(9.68, -2.35), 79.6, 0.15>.  Distance to center: 0.04, Distance from start 44.74, Lidar 1.5, 3.6, 5.3, 7.5, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 71.21.\n",
      "Iteration 360.  State is <(9.71, -2.23), 73.6, 0.10>.  Distance to center: 0.04, Distance from start 44.87, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 71.41.\n",
      "Iteration 361.  State is <(9.74, -2.11), 79.6, 0.15>.  Distance to center: 0.04, Distance from start 44.99, Lidar 1.4, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 71.61.\n",
      "Iteration 362.  State is <(9.76, -1.98), 73.6, 0.10>.  Distance to center: 0.04, Distance from start 45.12, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 71.81.\n",
      "Iteration 363.  State is <(9.79, -1.86), 79.6, 0.15>.  Distance to center: 0.03, Distance from start 45.24, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 72.01.\n",
      "Iteration 364.  State is <(9.81, -1.74), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 45.37, Lidar 1.5, 4.0, 5.7, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 72.21.\n",
      "Iteration 365.  State is <(9.83, -1.62), 79.6, 0.15>.  Distance to center: 0.04, Distance from start 45.49, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 72.41.\n",
      "Iteration 366.  State is <(9.84, -1.49), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 45.62, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 72.61.\n",
      "Iteration 367.  State is <(9.86, -1.37), 79.6, 0.15>.  Distance to center: 0.04, Distance from start 45.74, Lidar 1.4, 3.0, 4.3, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 72.81.\n",
      "Iteration 368.  State is <(9.88, -1.25), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 45.87, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 73.00.\n",
      "Iteration 369.  State is <(9.90, -1.12), 79.6, 0.15>.  Distance to center: 0.04, Distance from start 46.00, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 73.20.\n",
      "Iteration 370.  State is <(9.91, -1.00), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 46.12, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 73.40.\n",
      "Iteration 371.  State is <(9.93, -0.87), 79.6, 0.15>.  Distance to center: 0.03, Distance from start 46.25, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 73.60.\n",
      "Iteration 372.  State is <(9.95, -0.75), 85.6, 0.10>.  Distance to center: 0.02, Distance from start 46.37, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 73.80.\n",
      "Iteration 373.  State is <(9.95, -0.63), 91.6, 0.15>.  Distance to center: 0.03, Distance from start 46.50, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.00.\n",
      "Iteration 374.  State is <(9.95, -0.50), 85.6, 0.10>.  Distance to center: 0.03, Distance from start 46.62, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 74.20.\n",
      "Iteration 375.  State is <(9.95, -0.38), 91.6, 0.15>.  Distance to center: 0.04, Distance from start 46.75, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.40.\n",
      "Iteration 376.  State is <(9.96, -0.25), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 46.87, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 74.60.\n",
      "Iteration 377.  State is <(9.96, -0.13), 91.6, 0.15>.  Distance to center: 0.04, Distance from start 47.00, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 74.80.\n",
      "Iteration 378.  State is <(9.96, -0.00), 85.6, 0.10>.  Distance to center: 0.04, Distance from start 47.12, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 75.00.\n",
      "Iteration 379.  State is <(9.96, 0.12), 91.6, 0.15>.  Distance to center: 0.04, Distance from start 47.25, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 75.20.\n",
      "Iteration 380.  State is <(9.96, 0.25), 85.6, 0.10>.  Distance to center: 0.03, Distance from start 47.37, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 75.40.\n",
      "Iteration 381.  State is <(9.97, 0.37), 91.6, 0.15>.  Distance to center: 0.03, Distance from start 47.50, Lidar 1.4, 3.2, 4.5, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 75.60.\n",
      "Iteration 382.  State is <(9.96, 0.50), 97.6, 0.10>.  Distance to center: 0.03, Distance from start 47.62, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 75.79.\n",
      "Iteration 383.  State is <(9.95, 0.62), 91.6, 0.15>.  Distance to center: 0.03, Distance from start 47.75, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 75.99.\n",
      "Iteration 384.  State is <(9.94, 0.75), 97.6, 0.10>.  Distance to center: 0.03, Distance from start 47.87, Lidar 1.5, 3.6, 5.3, 7.5, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 76.19.\n",
      "Iteration 385.  State is <(9.93, 0.87), 91.6, 0.15>.  Distance to center: 0.03, Distance from start 48.00, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 76.39.\n",
      "Iteration 386.  State is <(9.92, 1.00), 97.6, 0.10>.  Distance to center: 0.03, Distance from start 48.12, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 76.59.\n",
      "Iteration 387.  State is <(9.91, 1.12), 91.6, 0.15>.  Distance to center: 0.02, Distance from start 48.25, Lidar 1.3, 2.7, 3.9, 5.6, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 76.79.\n",
      "Iteration 388.  State is <(9.91, 1.24), 97.6, 0.10>.  Distance to center: 0.02, Distance from start 48.37, Lidar 1.4, 3.2, 4.7, 6.8, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 76.99.\n",
      "Iteration 389.  State is <(9.88, 1.37), 103.6, 0.15>.  Distance to center: 0.02, Distance from start 48.50, Lidar 1.5, 3.9, 5.7, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 77.19.\n",
      "Iteration 390.  State is <(9.86, 1.49), 97.6, 0.10>.  Distance to center: 0.03, Distance from start 48.62, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 77.39.\n",
      "Iteration 391.  State is <(9.83, 1.61), 103.6, 0.15>.  Distance to center: 0.04, Distance from start 48.75, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 77.59.\n",
      "Iteration 392.  State is <(9.81, 1.73), 97.6, 0.10>.  Distance to center: 0.04, Distance from start 48.87, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 77.79.\n",
      "Iteration 393.  State is <(9.78, 1.86), 103.6, 0.15>.  Distance to center: 0.04, Distance from start 49.00, Lidar 1.5, 3.6, 5.2, 7.4, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 77.99.\n",
      "Iteration 394.  State is <(9.76, 1.98), 97.6, 0.10>.  Distance to center: 0.04, Distance from start 49.12, Lidar 1.3, 2.9, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 78.18.\n",
      "Iteration 395.  State is <(9.74, 2.10), 103.6, 0.15>.  Distance to center: 0.04, Distance from start 49.25, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 78.38.\n",
      "Iteration 396.  State is <(9.71, 2.22), 97.6, 0.10>.  Distance to center: 0.04, Distance from start 49.38, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 78.58.\n",
      "Iteration 397.  State is <(9.69, 2.35), 103.6, 0.15>.  Distance to center: 0.03, Distance from start 49.50, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 78.78.\n",
      "Iteration 398.  State is <(9.65, 2.47), 109.6, 0.10>.  Distance to center: 0.04, Distance from start 49.63, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 78.98.\n",
      "Iteration 399.  State is <(9.62, 2.59), 103.6, 0.15>.  Distance to center: 0.04, Distance from start 49.75, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 79.18.\n",
      "Iteration 400.  State is <(9.58, 2.71), 109.6, 0.10>.  Distance to center: 0.04, Distance from start 49.88, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 79.38.\n",
      "Iteration 401.  State is <(9.55, 2.83), 103.6, 0.15>.  Distance to center: 0.04, Distance from start 50.00, Lidar 1.4, 2.9, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 79.58.\n",
      "Iteration 402.  State is <(9.52, 2.95), 109.6, 0.10>.  Distance to center: 0.04, Distance from start 50.13, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 79.78.\n",
      "Iteration 403.  State is <(9.48, 3.07), 103.6, 0.15>.  Distance to center: 0.03, Distance from start 50.25, Lidar 1.3, 2.8, 4.0, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 79.98.\n",
      "Iteration 404.  State is <(9.45, 3.19), 109.6, 0.10>.  Distance to center: 0.03, Distance from start 50.38, Lidar 1.4, 3.3, 4.8, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 80.18.\n",
      "Iteration 405.  State is <(9.40, 3.30), 115.6, 0.15>.  Distance to center: 0.04, Distance from start 50.50, Lidar 1.6, 4.1, 5.9, 8.2, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 80.38.\n",
      "Iteration 406.  State is <(9.35, 3.42), 109.6, 0.10>.  Distance to center: 0.05, Distance from start 50.63, Lidar 1.4, 3.2, 4.6, 6.6, 1.4, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 80.58.\n",
      "Iteration 407.  State is <(9.30, 3.53), 115.6, 0.15>.  Distance to center: 0.05, Distance from start 50.75, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 80.78.\n",
      "Iteration 408.  State is <(9.25, 3.65), 109.6, 0.10>.  Distance to center: 0.06, Distance from start 50.88, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 80.98.\n",
      "Iteration 409.  State is <(9.20, 3.76), 115.6, 0.15>.  Distance to center: 0.06, Distance from start 51.00, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 81.18.\n",
      "Iteration 410.  State is <(9.15, 3.88), 109.6, 0.10>.  Distance to center: 0.06, Distance from start 51.13, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 81.37.\n",
      "Iteration 411.  State is <(9.10, 3.99), 115.6, 0.15>.  Distance to center: 0.06, Distance from start 51.26, Lidar 1.5, 3.5, 5.1, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 81.57.\n",
      "Iteration 412.  State is <(9.05, 4.11), 109.6, 0.10>.  Distance to center: 0.06, Distance from start 51.38, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 81.77.\n",
      "Iteration 413.  State is <(9.01, 4.22), 115.6, 0.15>.  Distance to center: 0.05, Distance from start 51.51, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 81.97.\n",
      "Iteration 414.  State is <(8.96, 4.33), 109.6, 0.10>.  Distance to center: 0.05, Distance from start 51.63, Lidar 1.3, 2.7, 3.7, 5.4, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 82.17.\n",
      "Iteration 415.  State is <(8.91, 4.45), 115.6, 0.15>.  Distance to center: 0.04, Distance from start 51.76, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 82.37.\n",
      "Iteration 416.  State is <(8.85, 4.56), 121.6, 0.10>.  Distance to center: 0.05, Distance from start 51.88, Lidar 1.5, 3.8, 5.5, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 82.57.\n",
      "Iteration 417.  State is <(8.79, 4.67), 115.6, 0.15>.  Distance to center: 0.05, Distance from start 52.01, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 82.77.\n",
      "Iteration 418.  State is <(8.73, 4.78), 121.6, 0.10>.  Distance to center: 0.05, Distance from start 52.13, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 82.97.\n",
      "Iteration 419.  State is <(8.67, 4.89), 115.6, 0.15>.  Distance to center: 0.04, Distance from start 52.26, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 83.17.\n",
      "Iteration 420.  State is <(8.61, 5.00), 121.6, 0.10>.  Distance to center: 0.04, Distance from start 52.38, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 83.37.\n",
      "Iteration 421.  State is <(8.56, 5.11), 115.6, 0.15>.  Distance to center: 0.03, Distance from start 52.51, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 83.57.\n",
      "Iteration 422.  State is <(8.50, 5.22), 121.6, 0.10>.  Distance to center: 0.03, Distance from start 52.63, Lidar 1.4, 3.2, 4.6, 6.7, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 83.77.\n",
      "Iteration 423.  State is <(8.43, 5.32), 127.6, 0.15>.  Distance to center: 0.03, Distance from start 52.76, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 83.97.\n",
      "Iteration 424.  State is <(8.35, 5.43), 121.6, 0.10>.  Distance to center: 0.04, Distance from start 52.88, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 84.17.\n",
      "Iteration 425.  State is <(8.28, 5.53), 127.6, 0.15>.  Distance to center: 0.04, Distance from start 53.01, Lidar 1.5, 3.7, 5.4, 7.6, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 84.37.\n",
      "Iteration 426.  State is <(8.21, 5.63), 121.6, 0.10>.  Distance to center: 0.05, Distance from start 53.13, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 84.57.\n",
      "Iteration 427.  State is <(8.14, 5.73), 127.6, 0.15>.  Distance to center: 0.05, Distance from start 53.26, Lidar 1.5, 3.5, 5.1, 7.3, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 84.77.\n",
      "Iteration 428.  State is <(8.07, 5.83), 121.6, 0.10>.  Distance to center: 0.05, Distance from start 53.39, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 84.97.\n",
      "Iteration 429.  State is <(7.99, 5.94), 127.6, 0.15>.  Distance to center: 0.04, Distance from start 53.51, Lidar 1.4, 3.4, 4.8, 6.9, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 85.16.\n",
      "Iteration 430.  State is <(7.92, 6.04), 121.6, 0.10>.  Distance to center: 0.04, Distance from start 53.64, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 85.36.\n",
      "Iteration 431.  State is <(7.85, 6.14), 127.6, 0.15>.  Distance to center: 0.03, Distance from start 53.76, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 85.56.\n",
      "Iteration 432.  State is <(7.77, 6.24), 133.6, 0.10>.  Distance to center: 0.04, Distance from start 53.89, Lidar 1.5, 3.8, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 85.76.\n",
      "Iteration 433.  State is <(7.69, 6.33), 127.6, 0.15>.  Distance to center: 0.04, Distance from start 54.01, Lidar 1.4, 3.0, 4.3, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 85.96.\n",
      "Iteration 434.  State is <(7.61, 6.43), 133.6, 0.10>.  Distance to center: 0.04, Distance from start 54.14, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 86.16.\n",
      "Iteration 435.  State is <(7.53, 6.52), 127.6, 0.15>.  Distance to center: 0.04, Distance from start 54.26, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 86.36.\n",
      "Iteration 436.  State is <(7.45, 6.62), 133.6, 0.10>.  Distance to center: 0.03, Distance from start 54.39, Lidar 1.4, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 86.56.\n",
      "Iteration 437.  State is <(7.37, 6.71), 127.6, 0.15>.  Distance to center: 0.03, Distance from start 54.51, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 86.76.\n",
      "Iteration 438.  State is <(7.29, 6.81), 133.6, 0.10>.  Distance to center: 0.02, Distance from start 54.64, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 86.96.\n",
      "Iteration 439.  State is <(7.20, 6.89), 139.6, 0.15>.  Distance to center: 0.03, Distance from start 54.76, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.16.\n",
      "Iteration 440.  State is <(7.11, 6.98), 133.6, 0.10>.  Distance to center: 0.04, Distance from start 54.89, Lidar 1.4, 3.1, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 87.36.\n",
      "Iteration 441.  State is <(7.01, 7.06), 139.6, 0.15>.  Distance to center: 0.04, Distance from start 55.01, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.56.\n",
      "Iteration 442.  State is <(6.92, 7.15), 133.6, 0.10>.  Distance to center: 0.05, Distance from start 55.14, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 87.76.\n",
      "Iteration 443.  State is <(6.83, 7.23), 139.6, 0.15>.  Distance to center: 0.05, Distance from start 55.26, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 87.96.\n",
      "Iteration 444.  State is <(6.74, 7.32), 133.6, 0.10>.  Distance to center: 0.05, Distance from start 55.39, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 88.15.\n",
      "Iteration 445.  State is <(6.65, 7.40), 139.6, 0.15>.  Distance to center: 0.05, Distance from start 55.51, Lidar 1.5, 3.4, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 88.35.\n",
      "Iteration 446.  State is <(6.56, 7.49), 133.6, 0.10>.  Distance to center: 0.05, Distance from start 55.64, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 88.55.\n",
      "Iteration 447.  State is <(6.47, 7.57), 139.6, 0.15>.  Distance to center: 0.04, Distance from start 55.77, Lidar 1.4, 3.3, 4.7, 6.7, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 88.75.\n",
      "Iteration 448.  State is <(6.37, 7.65), 145.6, 0.10>.  Distance to center: 0.05, Distance from start 55.89, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 88.95.\n",
      "Iteration 449.  State is <(6.27, 7.73), 139.6, 0.15>.  Distance to center: 0.05, Distance from start 56.02, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 89.15.\n",
      "Iteration 450.  State is <(6.17, 7.80), 145.6, 0.10>.  Distance to center: 0.05, Distance from start 56.14, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 89.35.\n",
      "Iteration 451.  State is <(6.07, 7.88), 139.6, 0.15>.  Distance to center: 0.05, Distance from start 56.27, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 89.55.\n",
      "Iteration 452.  State is <(5.97, 7.96), 145.6, 0.10>.  Distance to center: 0.05, Distance from start 56.39, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 89.75.\n",
      "Iteration 453.  State is <(5.88, 8.04), 139.6, 0.15>.  Distance to center: 0.05, Distance from start 56.52, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 89.95.\n",
      "Iteration 454.  State is <(5.78, 8.11), 145.6, 0.10>.  Distance to center: 0.04, Distance from start 56.64, Lidar 1.4, 3.4, 4.9, 6.9, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 90.15.\n",
      "Iteration 455.  State is <(5.68, 8.19), 139.6, 0.15>.  Distance to center: 0.03, Distance from start 56.77, Lidar 1.3, 2.7, 3.8, 5.5, 1.7, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 90.35.\n",
      "Iteration 456.  State is <(5.58, 8.27), 145.6, 0.10>.  Distance to center: 0.03, Distance from start 56.89, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 90.55.\n",
      "Iteration 457.  State is <(5.47, 8.33), 151.6, 0.15>.  Distance to center: 0.03, Distance from start 57.02, Lidar 1.5, 3.8, 5.6, 7.9, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 90.75.\n",
      "Iteration 458.  State is <(5.37, 8.39), 145.6, 0.10>.  Distance to center: 0.04, Distance from start 57.14, Lidar 1.4, 3.0, 4.4, 6.3, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 90.95.\n",
      "Iteration 459.  State is <(5.26, 8.46), 151.6, 0.15>.  Distance to center: 0.04, Distance from start 57.27, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 91.15.\n",
      "Iteration 460.  State is <(5.15, 8.52), 145.6, 0.10>.  Distance to center: 0.04, Distance from start 57.39, Lidar 1.3, 2.9, 4.1, 6.0, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 91.35.\n",
      "Iteration 461.  State is <(5.04, 8.59), 151.6, 0.15>.  Distance to center: 0.04, Distance from start 57.52, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 91.55.\n",
      "Iteration 462.  State is <(4.94, 8.65), 145.6, 0.10>.  Distance to center: 0.04, Distance from start 57.64, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 91.74.\n",
      "Iteration 463.  State is <(4.83, 8.71), 151.6, 0.15>.  Distance to center: 0.04, Distance from start 57.77, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 91.94.\n",
      "Iteration 464.  State is <(4.72, 8.77), 157.6, 0.10>.  Distance to center: 0.04, Distance from start 57.90, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.14.\n",
      "Iteration 465.  State is <(4.61, 8.82), 151.6, 0.15>.  Distance to center: 0.05, Distance from start 58.02, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 92.34.\n",
      "Iteration 466.  State is <(4.49, 8.88), 157.6, 0.10>.  Distance to center: 0.05, Distance from start 58.15, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.54.\n",
      "Iteration 467.  State is <(4.38, 8.93), 151.6, 0.15>.  Distance to center: 0.05, Distance from start 58.27, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 92.74.\n",
      "Iteration 468.  State is <(4.27, 8.99), 157.6, 0.10>.  Distance to center: 0.05, Distance from start 58.40, Lidar 1.5, 3.6, 5.2, 7.4, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 92.94.\n",
      "Iteration 469.  State is <(4.16, 9.04), 151.6, 0.15>.  Distance to center: 0.05, Distance from start 58.52, Lidar 1.3, 2.9, 4.1, 5.9, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 93.14.\n",
      "Iteration 470.  State is <(4.05, 9.10), 157.6, 0.10>.  Distance to center: 0.04, Distance from start 58.65, Lidar 1.4, 3.4, 5.0, 7.1, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 93.34.\n",
      "Iteration 471.  State is <(3.93, 9.15), 151.6, 0.15>.  Distance to center: 0.04, Distance from start 58.77, Lidar 1.3, 2.7, 3.9, 5.6, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 93.54.\n",
      "Iteration 472.  State is <(3.82, 9.21), 157.6, 0.10>.  Distance to center: 0.03, Distance from start 58.90, Lidar 1.4, 3.2, 4.7, 6.7, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 93.74.\n",
      "Iteration 473.  State is <(3.70, 9.25), 163.6, 0.15>.  Distance to center: 0.04, Distance from start 59.02, Lidar 1.5, 3.9, 5.7, 8.0, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 93.94.\n",
      "Iteration 474.  State is <(3.58, 9.29), 157.6, 0.10>.  Distance to center: 0.04, Distance from start 59.15, Lidar 1.4, 3.1, 4.5, 6.4, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.14.\n",
      "Iteration 475.  State is <(3.47, 9.33), 163.6, 0.15>.  Distance to center: 0.05, Distance from start 59.27, Lidar 1.5, 3.8, 5.4, 7.7, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 94.34.\n",
      "Iteration 476.  State is <(3.35, 9.37), 157.6, 0.10>.  Distance to center: 0.05, Distance from start 59.40, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.54.\n",
      "Iteration 477.  State is <(3.23, 9.41), 163.6, 0.15>.  Distance to center: 0.05, Distance from start 59.52, Lidar 1.5, 3.6, 5.1, 7.3, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 94.74.\n",
      "Iteration 478.  State is <(3.11, 9.45), 157.6, 0.10>.  Distance to center: 0.05, Distance from start 59.65, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 94.94.\n",
      "Iteration 479.  State is <(2.99, 9.49), 163.6, 0.15>.  Distance to center: 0.05, Distance from start 59.78, Lidar 1.4, 3.4, 4.9, 7.0, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 95.14.\n",
      "Iteration 480.  State is <(2.88, 9.53), 157.6, 0.10>.  Distance to center: 0.05, Distance from start 59.90, Lidar 1.3, 2.7, 3.8, 5.5, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 95.34.\n",
      "Iteration 481.  State is <(2.76, 9.57), 163.6, 0.15>.  Distance to center: 0.04, Distance from start 60.03, Lidar 1.4, 3.2, 4.6, 6.6, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 95.53.\n",
      "Iteration 482.  State is <(2.64, 9.60), 169.6, 0.10>.  Distance to center: 0.04, Distance from start 60.15, Lidar 1.5, 3.9, 5.6, 7.9, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 95.73.\n",
      "Iteration 483.  State is <(2.52, 9.63), 163.6, 0.15>.  Distance to center: 0.05, Distance from start 60.28, Lidar 1.4, 3.1, 4.4, 6.3, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 95.93.\n",
      "Iteration 484.  State is <(2.39, 9.66), 169.6, 0.10>.  Distance to center: 0.05, Distance from start 60.40, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 96.13.\n",
      "Iteration 485.  State is <(2.27, 9.69), 163.6, 0.15>.  Distance to center: 0.05, Distance from start 60.53, Lidar 1.4, 2.9, 4.2, 6.0, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 96.33.\n",
      "Iteration 486.  State is <(2.15, 9.72), 169.6, 0.10>.  Distance to center: 0.04, Distance from start 60.65, Lidar 1.5, 3.5, 5.0, 7.2, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 96.53.\n",
      "Iteration 487.  State is <(2.03, 9.75), 163.6, 0.15>.  Distance to center: 0.04, Distance from start 60.78, Lidar 1.3, 2.8, 3.9, 5.7, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 96.73.\n",
      "Iteration 488.  State is <(1.91, 9.78), 169.6, 0.10>.  Distance to center: 0.03, Distance from start 60.90, Lidar 1.4, 3.3, 4.8, 6.8, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 96.93.\n",
      "Iteration 489.  State is <(1.79, 9.80), 175.6, 0.15>.  Distance to center: 0.04, Distance from start 61.03, Lidar 1.5, 4.0, 5.8, 8.1, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.13.\n",
      "Iteration 490.  State is <(1.66, 9.81), 169.6, 0.10>.  Distance to center: 0.05, Distance from start 61.15, Lidar 1.4, 3.2, 4.5, 6.5, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 97.33.\n",
      "Iteration 491.  State is <(1.54, 9.83), 175.6, 0.15>.  Distance to center: 0.05, Distance from start 61.28, Lidar 1.5, 3.8, 5.5, 7.8, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.53.\n",
      "Iteration 492.  State is <(1.41, 9.84), 169.6, 0.10>.  Distance to center: 0.06, Distance from start 61.40, Lidar 1.4, 3.0, 4.3, 6.2, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 97.73.\n",
      "Iteration 493.  State is <(1.29, 9.86), 175.6, 0.15>.  Distance to center: 0.06, Distance from start 61.53, Lidar 1.5, 3.7, 5.3, 7.5, 1.3, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 97.93.\n",
      "Iteration 494.  State is <(1.17, 9.87), 169.6, 0.10>.  Distance to center: 0.06, Distance from start 61.66, Lidar 1.4, 2.9, 4.1, 5.9, 1.5, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 98.13.\n",
      "Iteration 495.  State is <(1.04, 9.89), 175.6, 0.15>.  Distance to center: 0.06, Distance from start 61.78, Lidar 1.5, 3.5, 5.0, 7.1, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 98.33.\n",
      "Iteration 496.  State is <(0.92, 9.90), 169.6, 0.10>.  Distance to center: 0.06, Distance from start 61.91, Lidar 1.3, 2.8, 3.9, 5.6, 1.6, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 98.53.\n",
      "Iteration 497.  State is <(0.79, 9.92), 175.6, 0.15>.  Distance to center: 0.05, Distance from start 62.03, Lidar 1.4, 3.3, 4.7, 6.8, 1.4, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 98.73.\n",
      "Iteration 498.  State is <(0.67, 9.93), 169.6, 0.10>.  Distance to center: 0.05, Distance from start 62.16, Lidar 1.3, 2.6, 3.7, 5.3, 1.7, Velocity 0.10, Choosing action ('left', 'brake'), reward 0.20 and totalReward 98.93.\n",
      "Iteration 499.  State is <(0.55, 9.95), 175.6, 0.15>.  Distance to center: 0.04, Distance from start 62.28, Lidar 1.4, 3.1, 4.4, 6.4, 1.5, Velocity 0.15, Choosing action ('right', 'accelerate'), reward 0.20 and totalReward 99.13.\n",
      "Iteration 500.  State is <(0.42, 9.95), 181.6, 0.10>.  Distance to center: 0.04, Distance from start 62.41, Lidar 1.5, 3.7, 5.4, 7.7, 1.3, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 99.33.\n",
      "Iteration 501.  State is <(0.30, 9.95), 175.6, 0.15>.  Distance to center: 0.04, Distance from start 62.53, Lidar 1.4, 3.0, 4.2, 6.1, 1.5, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 99.53.\n",
      "Iteration 502.  State is <(0.17, 9.96), 181.6, 0.10>.  Distance to center: 0.04, Distance from start 62.66, Lidar 1.5, 3.6, 5.1, 7.3, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 0.20 and totalReward 99.72.\n",
      "Iteration 503.  State is <(0.05, 9.96), 175.6, 0.15>.  Distance to center: 0.04, Distance from start 62.78, Lidar 1.3, 2.8, 4.0, 5.8, 1.6, Velocity 0.15, Choosing action ('left', 'accelerate'), reward 0.20 and totalReward 99.92.\n",
      "Iteration 504.  State is <(-0.08, 9.97), 181.6, 0.10>.  Distance to center: 0.03, Distance from start 0.08, Lidar 1.4, 3.4, 4.8, 7.0, 1.4, Velocity 0.10, Choosing action ('right', 'brake'), reward 15.13 and totalReward 115.05.\n",
      "\n",
      "Average speed = 0.125\n",
      "Maximum speed = 0.150\n",
      "Final score = 115.05376949565061\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
